{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0210926-2a16-4059-96c5-a7bcf067527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0b8f4a0-6d80-4ab2-892b-cf54c1a0a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-small-echo.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cc84e58-0434-4dd3-978c-dfb9627a781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open yaml config as a strema and load into config_dict\n",
    "with open(path_to_config, \"r\") as stream:\n",
    "    try:\n",
    "        config_dict = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Configuration load failed!\")\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8562818d-3231-4c66-951f-7303a1a6b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "416ac967-84aa-4ded-ab89-88723ebfe249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load a trained model and vocabulary that you have fine-tuned\n",
    "model = GPT2LMHeadModel.from_pretrained(config_dict[\"output_model_dir\"])\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(config_dict[\"output_tokenizer_dir\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d180588a-3f5d-4168-9e41-80636eaa182f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "effb3ed8-12db-44b5-a9de-91569fac4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_text = \"Instruction: The following is an interaction between a therapist and a client. Act as the therapist and give a reflection to the client's response. The reflection must be a statement and not a question. The reflection must be a rephrasing of the client's response.\\nTherapist: It's great to hear you want to reduce your smoking. What would it look like when you have reduced your smoking addiction?\\nClient: Better health condition, less money spent but more stress.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eb78eca-95b3-40b0-a01d-963f40c0a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_text = \"Therapist: Now, what is one thing about your smoking habit that you would like to change?\\nClient: I'd like to quit completely. Maybe not quit entirely, but go down to 1 a day or only smoke during social gatherings.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65e478af-2383-463c-9a46-93714c014da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "charlie_text = \"Instruction: The following is an interaction between a therapist and a client. Act as the therapist and give a reflection to the client's response. The reflection must be a statement and not a question. The reflection must be a rephrasing of the client's response.\\n\\n###\\n\\nTherapist: What else do you dislike about smoking?\\nClient: The money i spend on cigarettes\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bccec30-ee13-4576-8722-78a9d841d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_text = \"Instruction: The following is an interaction between a therapist and a client. Act as the therapist and give a reflection to the client's response. The reflection must be a statement and not a question. The reflection must be a rephrasing of the client's response.\\n\\nTherapist: What else do you dislike about smoking?\\nClient: The money i spend on cigarettes\\n\\n###\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a6d1830-f5b6-462a-930e-54477bd7853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_text = \"### Instruction: The following is an interaction between a therapist and a client. Act as the therapist and give a reflection to the client's response. The reflection must be a statement and not a question. The reflection must be a rephrasing of the client's response.\\n\\n Conversation:\\nTherapist: What else do you dislike about smoking?\\nClient: The money i spend on cigarettes\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e473e87-5e80-4a0c-9ae9-c72fd7304d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/instruct-reflections/holdout-set/holdout-instruct-question-answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1437d930-044d-4be5-bb75-ebe43e48e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PromptAndResponse', 'instruction', 'question', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d87b9f5-1bd9-46ba-8f30-c45ce06f17bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    alpha = \"Instruction: \" + row[\"instruction\"] + \"\\n\"  \"Therapist: \" + row[\"question\"] + \"\\n\" + \"Client: \" + row[\"answer\"] + \"\\n\"\n",
    "    beta = \"Therapist: \" + row[\"question\"] + \"\\n\" + \"Client: \" + row[\"answer\"] + \"\\n\"\n",
    "    charlie = \"Instruction: \" + row[\"instruction\"] + \"\\n\\n###\\n\\n\"  \"Therapist: \" + row[\"question\"] + \"\\n\" + \"Client: \" + row[\"answer\"] + \"\\n\"\n",
    "    delta = \"instruction: \" + row[\"instruction\"] + \"\\n\\n\" + \"Therapist: \" + row[\"question\"] + \"\\n\" + \"Client: \" + row[\"answer\"] + \"\\n\\n###\\n\\n\\n\"\n",
    "    echo = \"### Instruction:\\n\" + row[\"instruction\"] + \"\\n\\n\" + \"### Conversation:\\n\" + \"Therapist: \" + row[\"question\"] + \"\\n\" + \"Client: \" + row[\"answer\"] + \"\\n\"\n",
    "    \n",
    "    df.loc[idx, 'alphaInput'] = alpha\n",
    "    df.loc[idx, 'betaInput'] = beta\n",
    "    df.loc[idx, 'charlieInput'] = charlie\n",
    "    df.loc[idx, 'deltaInput'] = delta\n",
    "    df.loc[idx, 'echoInput'] = echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f345c7a-32de-48ca-bfb9-9434f8d4dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stop_criteria.py contains the class definition for StopTokenCriteria. \n",
    "'''\n",
    "\n",
    "# The model.generate() function accepts as an argument a child of the abstract base class StoppingCriteria\n",
    "# that defines the stopping criteria of the autoregressive loop embedded in model.generate(). The criteria defined\n",
    "# is evaluated after each token is generated.\n",
    "# StopTokenCriteria defines a callable object StoppingCriteria that stops (returns true) when a \\n character is the \n",
    "# latest character generated and the string \"Reflection:\" has been previously generated.\n",
    "class StopTokenCriteria(StoppingCriteria):\n",
    "    \n",
    "    def __init__(self, stop_token, tokenizer):\n",
    "        self.stop_token = stop_token\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        \n",
    "        # if input_ids[-1][-1] (the latest token generated) is equal to the stop token\n",
    "        stopGenerate = self.tokenizer.decode(input_ids[-1][-1]) == self.stop_token\n",
    "        \n",
    "        # if stopGenerate AND if the string \"Reflection:\" has been generated since the beginning of the\n",
    "        # autoregressive loop\n",
    "        stopGenerate = stopGenerate and \"Therapist:\" in self.tokenizer.decode(input_ids[-1])\n",
    "        \n",
    "        return stopGenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e377fc2-fb3c-48fa-b61a-a9d6934fb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model(model, tokenizer, config_dict, text, stopping_token=\"\\n\"):\n",
    "    model.eval()\n",
    "    generation_config = config_dict['refgen']\n",
    "    config = config_dict\n",
    "    use_stopping_criteria = True\n",
    "\n",
    "\n",
    "    # encode the input text into tokens using the tokenizer\n",
    "    tokenized_text = tokenizer.encode(\n",
    "        text, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "    encodings_dict = tokenizer(text, truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "    input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "    input_ids = tokenized_text.to(device)\n",
    "\n",
    "    # sample model with generate() using no tokens, just let it generate\n",
    "    with torch.no_grad():\n",
    "        sample_outputs = model.generate(input_ids,\n",
    "                                        bos_token_id=tokenizer.bos_token_id,\n",
    "                                        temperature = 0.8,\n",
    "                                        # flag to use a sampling technique or greedy\n",
    "                                        do_sample=generation_config['do_sample'],\n",
    "                                        # penalize model for duplicating words\n",
    "                                        repetition_penalty = 1.1,\n",
    "                                        pad_token_id=tokenizer.pad_token_id,\n",
    "                                        # of proposed words, only select from top k of them\n",
    "                                        top_k=generation_config['top_k'],\n",
    "                                        # max amount of tokens to generate\n",
    "                                        max_length=256,\n",
    "                                        stopping_criteria=StoppingCriteriaList([StopTokenCriteria(stopping_token, tokenizer)] if use_stopping_criteria else []),\n",
    "                                        # of propsed words, select from the words that add up to top_p value\n",
    "                                        # e.g. top_p=0.26 x(0.15),y(0.1),z(0.05)\n",
    "                                        # only select from x and y (0.15+0.1+0.05=0.3 which is too high)\n",
    "                                        top_p=generation_config['top_p'],\n",
    "                                        # num of independently computed returned sequences for each element in the batch.\n",
    "                                        num_return_sequences=1\n",
    "                                       )\n",
    "        output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0547940-b478-4128-a2a8-4970dcfd000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../configs/gpt2-small-delta.yaml'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4820699e-ea58-4756-b0b7-9ab4a313262e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1321\n",
      "1: 1321\n",
      "2: 1321\n",
      "3: 1321\n",
      "4: 1321\n",
      "5: 1321\n",
      "6: 1321\n",
      "7: 1321\n",
      "8: 1321\n",
      "9: 1321\n",
      "10: 1321\n",
      "11: 1321\n",
      "12: 1321\n",
      "13: 1321\n",
      "14: 1321\n",
      "15: 1321\n",
      "16: 1321\n",
      "17: 1321\n",
      "18: 1321\n",
      "19: 1321\n",
      "20: 1321\n",
      "21: 1321\n",
      "22: 1321\n",
      "23: 1321\n",
      "24: 1321\n",
      "25: 1321\n",
      "26: 1321\n",
      "27: 1321\n",
      "28: 1321\n",
      "29: 1321\n",
      "30: 1321\n",
      "31: 1321\n",
      "32: 1321\n",
      "33: 1321\n",
      "34: 1321\n",
      "35: 1321\n",
      "36: 1321\n",
      "37: 1321\n",
      "38: 1321\n",
      "39: 1321\n",
      "40: 1321\n",
      "41: 1321\n",
      "42: 1321\n",
      "43: 1321\n",
      "44: 1321\n",
      "45: 1321\n",
      "46: 1321\n",
      "47: 1321\n",
      "48: 1321\n",
      "49: 1321\n",
      "50: 1321\n",
      "51: 1321\n",
      "52: 1321\n",
      "53: 1321\n",
      "54: 1321\n",
      "55: 1321\n",
      "56: 1321\n",
      "57: 1321\n",
      "58: 1321\n",
      "59: 1321\n",
      "60: 1321\n",
      "61: 1321\n",
      "62: 1321\n",
      "63: 1321\n",
      "64: 1321\n",
      "65: 1321\n",
      "66: 1321\n",
      "67: 1321\n",
      "68: 1321\n",
      "69: 1321\n",
      "70: 1321\n",
      "71: 1321\n",
      "72: 1321\n",
      "73: 1321\n",
      "74: 1321\n",
      "75: 1321\n",
      "76: 1321\n",
      "77: 1321\n",
      "78: 1321\n",
      "79: 1321\n",
      "80: 1321\n",
      "81: 1321\n",
      "82: 1321\n",
      "83: 1321\n",
      "84: 1321\n",
      "85: 1321\n",
      "86: 1321\n",
      "87: 1321\n",
      "88: 1321\n",
      "89: 1321\n",
      "90: 1321\n",
      "91: 1321\n",
      "92: 1321\n",
      "93: 1321\n",
      "94: 1321\n",
      "95: 1321\n",
      "96: 1321\n",
      "97: 1321\n",
      "98: 1321\n",
      "99: 1321\n",
      "100: 1321\n",
      "101: 1321\n",
      "102: 1321\n",
      "103: 1321\n",
      "104: 1321\n",
      "105: 1321\n",
      "106: 1321\n",
      "107: 1321\n",
      "108: 1321\n",
      "109: 1321\n",
      "110: 1321\n",
      "111: 1321\n",
      "112: 1321\n",
      "113: 1321\n",
      "114: 1321\n",
      "115: 1321\n",
      "116: 1321\n",
      "117: 1321\n",
      "118: 1321\n",
      "119: 1321\n",
      "120: 1321\n",
      "121: 1321\n",
      "122: 1321\n",
      "123: 1321\n",
      "124: 1321\n",
      "125: 1321\n",
      "126: 1321\n",
      "127: 1321\n",
      "128: 1321\n",
      "129: 1321\n",
      "130: 1321\n",
      "131: 1321\n",
      "132: 1321\n",
      "133: 1321\n",
      "134: 1321\n",
      "135: 1321\n",
      "136: 1321\n",
      "137: 1321\n",
      "138: 1321\n",
      "139: 1321\n",
      "140: 1321\n",
      "141: 1321\n",
      "142: 1321\n",
      "143: 1321\n",
      "144: 1321\n",
      "145: 1321\n",
      "146: 1321\n",
      "147: 1321\n",
      "148: 1321\n",
      "149: 1321\n",
      "150: 1321\n",
      "151: 1321\n",
      "152: 1321\n",
      "153: 1321\n",
      "154: 1321\n",
      "155: 1321\n",
      "156: 1321\n",
      "157: 1321\n",
      "158: 1321\n",
      "159: 1321\n",
      "160: 1321\n",
      "161: 1321\n",
      "162: 1321\n",
      "163: 1321\n",
      "164: 1321\n",
      "165: 1321\n",
      "166: 1321\n",
      "167: 1321\n",
      "168: 1321\n",
      "169: 1321\n",
      "170: 1321\n",
      "171: 1321\n",
      "172: 1321\n",
      "173: 1321\n",
      "174: 1321\n",
      "175: 1321\n",
      "176: 1321\n",
      "177: 1321\n",
      "178: 1321\n",
      "179: 1321\n",
      "180: 1321\n",
      "181: 1321\n",
      "182: 1321\n",
      "183: 1321\n",
      "184: 1321\n",
      "185: 1321\n",
      "186: 1321\n",
      "187: 1321\n",
      "188: 1321\n",
      "189: 1321\n",
      "190: 1321\n",
      "191: 1321\n",
      "192: 1321\n",
      "193: 1321\n",
      "194: 1321\n",
      "195: 1321\n",
      "196: 1321\n",
      "197: 1321\n",
      "198: 1321\n",
      "199: 1321\n",
      "200: 1321\n",
      "201: 1321\n",
      "202: 1321\n",
      "203: 1321\n",
      "204: 1321\n",
      "205: 1321\n",
      "206: 1321\n",
      "207: 1321\n",
      "208: 1321\n",
      "209: 1321\n",
      "210: 1321\n",
      "211: 1321\n",
      "212: 1321\n",
      "213: 1321\n",
      "214: 1321\n",
      "215: 1321\n",
      "216: 1321\n",
      "217: 1321\n",
      "218: 1321\n",
      "219: 1321\n",
      "220: 1321\n",
      "221: 1321\n",
      "222: 1321\n",
      "223: 1321\n",
      "224: 1321\n",
      "225: 1321\n",
      "226: 1321\n",
      "227: 1321\n",
      "228: 1321\n",
      "229: 1321\n",
      "230: 1321\n",
      "231: 1321\n",
      "232: 1321\n",
      "233: 1321\n",
      "234: 1321\n",
      "235: 1321\n",
      "236: 1321\n",
      "237: 1321\n",
      "238: 1321\n",
      "239: 1321\n",
      "240: 1321\n",
      "241: 1321\n",
      "242: 1321\n",
      "243: 1321\n",
      "244: 1321\n",
      "245: 1321\n",
      "246: 1321\n",
      "247: 1321\n",
      "248: 1321\n",
      "249: 1321\n",
      "250: 1321\n",
      "251: 1321\n",
      "252: 1321\n",
      "253: 1321\n",
      "254: 1321\n",
      "255: 1321\n",
      "256: 1321\n",
      "257: 1321\n",
      "258: 1321\n",
      "259: 1321\n",
      "260: 1321\n",
      "261: 1321\n",
      "262: 1321\n",
      "263: 1321\n",
      "264: 1321\n",
      "265: 1321\n",
      "266: 1321\n",
      "267: 1321\n",
      "268: 1321\n",
      "269: 1321\n",
      "270: 1321\n",
      "271: 1321\n",
      "272: 1321\n",
      "273: 1321\n",
      "274: 1321\n",
      "275: 1321\n",
      "276: 1321\n",
      "277: 1321\n",
      "278: 1321\n",
      "279: 1321\n",
      "280: 1321\n",
      "281: 1321\n",
      "282: 1321\n",
      "283: 1321\n",
      "284: 1321\n",
      "285: 1321\n",
      "286: 1321\n",
      "287: 1321\n",
      "288: 1321\n",
      "289: 1321\n",
      "290: 1321\n",
      "291: 1321\n",
      "292: 1321\n",
      "293: 1321\n",
      "294: 1321\n",
      "295: 1321\n",
      "296: 1321\n",
      "297: 1321\n",
      "298: 1321\n",
      "299: 1321\n",
      "300: 1321\n",
      "301: 1321\n",
      "302: 1321\n",
      "303: 1321\n",
      "304: 1321\n",
      "305: 1321\n",
      "306: 1321\n",
      "307: 1321\n",
      "308: 1321\n",
      "309: 1321\n",
      "310: 1321\n",
      "311: 1321\n",
      "312: 1321\n",
      "313: 1321\n",
      "314: 1321\n",
      "315: 1321\n",
      "316: 1321\n",
      "317: 1321\n",
      "318: 1321\n",
      "319: 1321\n",
      "320: 1321\n",
      "321: 1321\n",
      "322: 1321\n",
      "323: 1321\n",
      "324: 1321\n",
      "325: 1321\n",
      "326: 1321\n",
      "327: 1321\n",
      "328: 1321\n",
      "329: 1321\n",
      "330: 1321\n",
      "331: 1321\n",
      "332: 1321\n",
      "333: 1321\n",
      "334: 1321\n",
      "335: 1321\n",
      "336: 1321\n",
      "337: 1321\n",
      "338: 1321\n",
      "339: 1321\n",
      "340: 1321\n",
      "341: 1321\n",
      "342: 1321\n",
      "343: 1321\n",
      "344: 1321\n",
      "345: 1321\n",
      "346: 1321\n",
      "347: 1321\n",
      "348: 1321\n",
      "349: 1321\n",
      "350: 1321\n",
      "351: 1321\n",
      "352: 1321\n",
      "353: 1321\n",
      "354: 1321\n",
      "355: 1321\n",
      "356: 1321\n",
      "357: 1321\n",
      "358: 1321\n",
      "359: 1321\n",
      "360: 1321\n",
      "361: 1321\n",
      "362: 1321\n",
      "363: 1321\n",
      "364: 1321\n",
      "365: 1321\n",
      "366: 1321\n",
      "367: 1321\n",
      "368: 1321\n",
      "369: 1321\n",
      "370: 1321\n",
      "371: 1321\n",
      "372: 1321\n",
      "373: 1321\n",
      "374: 1321\n",
      "375: 1321\n",
      "376: 1321\n",
      "377: 1321\n",
      "378: 1321\n",
      "379: 1321\n",
      "380: 1321\n",
      "381: 1321\n",
      "382: 1321\n",
      "383: 1321\n",
      "384: 1321\n",
      "385: 1321\n",
      "386: 1321\n",
      "387: 1321\n",
      "388: 1321\n",
      "389: 1321\n",
      "390: 1321\n",
      "391: 1321\n",
      "392: 1321\n",
      "393: 1321\n",
      "394: 1321\n",
      "395: 1321\n",
      "396: 1321\n",
      "397: 1321\n",
      "398: 1321\n",
      "399: 1321\n",
      "400: 1321\n",
      "401: 1321\n",
      "402: 1321\n",
      "403: 1321\n",
      "404: 1321\n",
      "405: 1321\n",
      "406: 1321\n",
      "407: 1321\n",
      "408: 1321\n",
      "409: 1321\n",
      "410: 1321\n",
      "411: 1321\n",
      "412: 1321\n",
      "413: 1321\n",
      "414: 1321\n",
      "415: 1321\n",
      "416: 1321\n",
      "417: 1321\n",
      "418: 1321\n",
      "419: 1321\n",
      "420: 1321\n",
      "421: 1321\n",
      "422: 1321\n",
      "423: 1321\n",
      "424: 1321\n",
      "425: 1321\n",
      "426: 1321\n",
      "427: 1321\n",
      "428: 1321\n",
      "429: 1321\n",
      "430: 1321\n",
      "431: 1321\n",
      "432: 1321\n",
      "433: 1321\n",
      "434: 1321\n",
      "435: 1321\n",
      "436: 1321\n",
      "437: 1321\n",
      "438: 1321\n",
      "439: 1321\n",
      "440: 1321\n",
      "441: 1321\n",
      "442: 1321\n",
      "443: 1321\n",
      "444: 1321\n",
      "445: 1321\n",
      "446: 1321\n",
      "447: 1321\n",
      "448: 1321\n",
      "449: 1321\n",
      "450: 1321\n",
      "451: 1321\n",
      "452: 1321\n",
      "453: 1321\n",
      "454: 1321\n",
      "455: 1321\n",
      "456: 1321\n",
      "457: 1321\n",
      "458: 1321\n",
      "459: 1321\n",
      "460: 1321\n",
      "461: 1321\n",
      "462: 1321\n",
      "463: 1321\n",
      "464: 1321\n",
      "465: 1321\n",
      "466: 1321\n",
      "467: 1321\n",
      "468: 1321\n",
      "469: 1321\n",
      "470: 1321\n",
      "471: 1321\n",
      "472: 1321\n",
      "473: 1321\n",
      "474: 1321\n",
      "475: 1321\n",
      "476: 1321\n",
      "477: 1321\n",
      "478: 1321\n",
      "479: 1321\n",
      "480: 1321\n",
      "481: 1321\n",
      "482: 1321\n",
      "483: 1321\n",
      "484: 1321\n",
      "485: 1321\n",
      "486: 1321\n",
      "487: 1321\n",
      "488: 1321\n",
      "489: 1321\n",
      "490: 1321\n",
      "491: 1321\n",
      "492: 1321\n",
      "493: 1321\n",
      "494: 1321\n",
      "495: 1321\n",
      "496: 1321\n",
      "497: 1321\n",
      "498: 1321\n",
      "499: 1321\n",
      "500: 1321\n",
      "501: 1321\n",
      "502: 1321\n",
      "503: 1321\n",
      "504: 1321\n",
      "505: 1321\n",
      "506: 1321\n",
      "507: 1321\n",
      "508: 1321\n",
      "509: 1321\n",
      "510: 1321\n",
      "511: 1321\n",
      "512: 1321\n",
      "513: 1321\n",
      "514: 1321\n",
      "515: 1321\n",
      "516: 1321\n",
      "517: 1321\n",
      "518: 1321\n",
      "519: 1321\n",
      "520: 1321\n",
      "521: 1321\n",
      "522: 1321\n",
      "523: 1321\n",
      "524: 1321\n",
      "525: 1321\n",
      "526: 1321\n",
      "527: 1321\n",
      "528: 1321\n",
      "529: 1321\n",
      "530: 1321\n",
      "531: 1321\n",
      "532: 1321\n",
      "533: 1321\n",
      "534: 1321\n",
      "535: 1321\n",
      "536: 1321\n",
      "537: 1321\n",
      "538: 1321\n",
      "539: 1321\n",
      "540: 1321\n",
      "541: 1321\n",
      "542: 1321\n",
      "543: 1321\n",
      "544: 1321\n",
      "545: 1321\n",
      "546: 1321\n",
      "547: 1321\n",
      "548: 1321\n",
      "549: 1321\n",
      "550: 1321\n",
      "551: 1321\n",
      "552: 1321\n",
      "553: 1321\n",
      "554: 1321\n",
      "555: 1321\n",
      "556: 1321\n",
      "557: 1321\n",
      "558: 1321\n",
      "559: 1321\n",
      "560: 1321\n",
      "561: 1321\n",
      "562: 1321\n",
      "563: 1321\n",
      "564: 1321\n",
      "565: 1321\n",
      "566: 1321\n",
      "567: 1321\n",
      "568: 1321\n",
      "569: 1321\n",
      "570: 1321\n",
      "571: 1321\n",
      "572: 1321\n",
      "573: 1321\n",
      "574: 1321\n",
      "575: 1321\n",
      "576: 1321\n",
      "577: 1321\n",
      "578: 1321\n",
      "579: 1321\n",
      "580: 1321\n",
      "581: 1321\n",
      "582: 1321\n",
      "583: 1321\n",
      "584: 1321\n",
      "585: 1321\n",
      "586: 1321\n",
      "587: 1321\n",
      "588: 1321\n",
      "589: 1321\n",
      "590: 1321\n",
      "591: 1321\n",
      "592: 1321\n",
      "593: 1321\n",
      "594: 1321\n",
      "595: 1321\n",
      "596: 1321\n",
      "597: 1321\n",
      "598: 1321\n",
      "599: 1321\n",
      "600: 1321\n",
      "601: 1321\n",
      "602: 1321\n",
      "603: 1321\n",
      "604: 1321\n",
      "605: 1321\n",
      "606: 1321\n",
      "607: 1321\n",
      "608: 1321\n",
      "609: 1321\n",
      "610: 1321\n",
      "611: 1321\n",
      "612: 1321\n",
      "613: 1321\n",
      "614: 1321\n",
      "615: 1321\n",
      "616: 1321\n",
      "617: 1321\n",
      "618: 1321\n",
      "619: 1321\n",
      "620: 1321\n",
      "621: 1321\n",
      "622: 1321\n",
      "623: 1321\n",
      "624: 1321\n",
      "625: 1321\n",
      "626: 1321\n",
      "627: 1321\n",
      "628: 1321\n",
      "629: 1321\n",
      "630: 1321\n",
      "631: 1321\n",
      "632: 1321\n",
      "633: 1321\n",
      "634: 1321\n",
      "635: 1321\n",
      "636: 1321\n",
      "637: 1321\n",
      "638: 1321\n",
      "639: 1321\n",
      "640: 1321\n",
      "641: 1321\n",
      "642: 1321\n",
      "643: 1321\n",
      "644: 1321\n",
      "645: 1321\n",
      "646: 1321\n",
      "647: 1321\n",
      "648: 1321\n",
      "649: 1321\n",
      "650: 1321\n",
      "651: 1321\n",
      "652: 1321\n",
      "653: 1321\n",
      "654: 1321\n",
      "655: 1321\n",
      "656: 1321\n",
      "657: 1321\n",
      "658: 1321\n",
      "659: 1321\n",
      "660: 1321\n",
      "661: 1321\n",
      "662: 1321\n",
      "663: 1321\n",
      "664: 1321\n",
      "665: 1321\n",
      "666: 1321\n",
      "667: 1321\n",
      "668: 1321\n",
      "669: 1321\n",
      "670: 1321\n",
      "671: 1321\n",
      "672: 1321\n",
      "673: 1321\n",
      "674: 1321\n",
      "675: 1321\n",
      "676: 1321\n",
      "677: 1321\n",
      "678: 1321\n",
      "679: 1321\n",
      "680: 1321\n",
      "681: 1321\n",
      "682: 1321\n",
      "683: 1321\n",
      "684: 1321\n",
      "685: 1321\n",
      "686: 1321\n",
      "687: 1321\n",
      "688: 1321\n",
      "689: 1321\n",
      "690: 1321\n",
      "691: 1321\n",
      "692: 1321\n",
      "693: 1321\n",
      "694: 1321\n",
      "695: 1321\n",
      "696: 1321\n",
      "697: 1321\n",
      "698: 1321\n",
      "699: 1321\n",
      "700: 1321\n",
      "701: 1321\n",
      "702: 1321\n",
      "703: 1321\n",
      "704: 1321\n",
      "705: 1321\n",
      "706: 1321\n",
      "707: 1321\n",
      "708: 1321\n",
      "709: 1321\n",
      "710: 1321\n",
      "711: 1321\n",
      "712: 1321\n",
      "713: 1321\n",
      "714: 1321\n",
      "715: 1321\n",
      "716: 1321\n",
      "717: 1321\n",
      "718: 1321\n",
      "719: 1321\n",
      "720: 1321\n",
      "721: 1321\n",
      "722: 1321\n",
      "723: 1321\n",
      "724: 1321\n",
      "725: 1321\n",
      "726: 1321\n",
      "727: 1321\n",
      "728: 1321\n",
      "729: 1321\n",
      "730: 1321\n",
      "731: 1321\n",
      "732: 1321\n",
      "733: 1321\n",
      "734: 1321\n",
      "735: 1321\n",
      "736: 1321\n",
      "737: 1321\n",
      "738: 1321\n",
      "739: 1321\n",
      "740: 1321\n",
      "741: 1321\n",
      "742: 1321\n",
      "743: 1321\n",
      "744: 1321\n",
      "745: 1321\n",
      "746: 1321\n",
      "747: 1321\n",
      "748: 1321\n",
      "749: 1321\n",
      "750: 1321\n",
      "751: 1321\n",
      "752: 1321\n",
      "753: 1321\n",
      "754: 1321\n",
      "755: 1321\n",
      "756: 1321\n",
      "757: 1321\n",
      "758: 1321\n",
      "759: 1321\n",
      "760: 1321\n",
      "761: 1321\n",
      "762: 1321\n",
      "763: 1321\n",
      "764: 1321\n",
      "765: 1321\n",
      "766: 1321\n",
      "767: 1321\n",
      "768: 1321\n",
      "769: 1321\n",
      "770: 1321\n",
      "771: 1321\n",
      "772: 1321\n",
      "773: 1321\n",
      "774: 1321\n",
      "775: 1321\n",
      "776: 1321\n",
      "777: 1321\n",
      "778: 1321\n",
      "779: 1321\n",
      "780: 1321\n",
      "781: 1321\n",
      "782: 1321\n",
      "783: 1321\n",
      "784: 1321\n",
      "785: 1321\n",
      "786: 1321\n",
      "787: 1321\n",
      "788: 1321\n",
      "789: 1321\n",
      "790: 1321\n",
      "791: 1321\n",
      "792: 1321\n",
      "793: 1321\n",
      "794: 1321\n",
      "795: 1321\n",
      "796: 1321\n",
      "797: 1321\n",
      "798: 1321\n",
      "799: 1321\n",
      "800: 1321\n",
      "801: 1321\n",
      "802: 1321\n",
      "803: 1321\n",
      "804: 1321\n",
      "805: 1321\n",
      "806: 1321\n",
      "807: 1321\n",
      "808: 1321\n",
      "809: 1321\n",
      "810: 1321\n",
      "811: 1321\n",
      "812: 1321\n",
      "813: 1321\n",
      "814: 1321\n",
      "815: 1321\n",
      "816: 1321\n",
      "817: 1321\n",
      "818: 1321\n",
      "819: 1321\n",
      "820: 1321\n",
      "821: 1321\n",
      "822: 1321\n",
      "823: 1321\n",
      "824: 1321\n",
      "825: 1321\n",
      "826: 1321\n",
      "827: 1321\n",
      "828: 1321\n",
      "829: 1321\n",
      "830: 1321\n",
      "831: 1321\n",
      "832: 1321\n",
      "833: 1321\n",
      "834: 1321\n",
      "835: 1321\n",
      "836: 1321\n",
      "837: 1321\n",
      "838: 1321\n",
      "839: 1321\n",
      "840: 1321\n",
      "841: 1321\n",
      "842: 1321\n",
      "843: 1321\n",
      "844: 1321\n",
      "845: 1321\n",
      "846: 1321\n",
      "847: 1321\n",
      "848: 1321\n",
      "849: 1321\n",
      "850: 1321\n",
      "851: 1321\n",
      "852: 1321\n",
      "853: 1321\n",
      "854: 1321\n",
      "855: 1321\n",
      "856: 1321\n",
      "857: 1321\n",
      "858: 1321\n",
      "859: 1321\n",
      "860: 1321\n",
      "861: 1321\n",
      "862: 1321\n",
      "863: 1321\n",
      "864: 1321\n",
      "865: 1321\n",
      "866: 1321\n",
      "867: 1321\n",
      "868: 1321\n",
      "869: 1321\n",
      "870: 1321\n",
      "871: 1321\n",
      "872: 1321\n",
      "873: 1321\n",
      "874: 1321\n",
      "875: 1321\n",
      "876: 1321\n",
      "877: 1321\n",
      "878: 1321\n",
      "879: 1321\n",
      "880: 1321\n",
      "881: 1321\n",
      "882: 1321\n",
      "883: 1321\n",
      "884: 1321\n",
      "885: 1321\n",
      "886: 1321\n",
      "887: 1321\n",
      "888: 1321\n",
      "889: 1321\n",
      "890: 1321\n",
      "891: 1321\n",
      "892: 1321\n",
      "893: 1321\n",
      "894: 1321\n",
      "895: 1321\n",
      "896: 1321\n",
      "897: 1321\n",
      "898: 1321\n",
      "899: 1321\n",
      "900: 1321\n",
      "901: 1321\n",
      "902: 1321\n",
      "903: 1321\n",
      "904: 1321\n",
      "905: 1321\n",
      "906: 1321\n",
      "907: 1321\n",
      "908: 1321\n",
      "909: 1321\n",
      "910: 1321\n",
      "911: 1321\n",
      "912: 1321\n",
      "913: 1321\n",
      "914: 1321\n",
      "915: 1321\n",
      "916: 1321\n",
      "917: 1321\n",
      "918: 1321\n",
      "919: 1321\n",
      "920: 1321\n",
      "921: 1321\n",
      "922: 1321\n",
      "923: 1321\n",
      "924: 1321\n",
      "925: 1321\n",
      "926: 1321\n",
      "927: 1321\n",
      "928: 1321\n",
      "929: 1321\n",
      "930: 1321\n",
      "931: 1321\n",
      "932: 1321\n",
      "933: 1321\n",
      "934: 1321\n",
      "935: 1321\n",
      "936: 1321\n",
      "937: 1321\n",
      "938: 1321\n",
      "939: 1321\n",
      "940: 1321\n",
      "941: 1321\n",
      "942: 1321\n",
      "943: 1321\n",
      "944: 1321\n",
      "945: 1321\n",
      "946: 1321\n",
      "947: 1321\n",
      "948: 1321\n",
      "949: 1321\n",
      "950: 1321\n",
      "951: 1321\n",
      "952: 1321\n",
      "953: 1321\n",
      "954: 1321\n",
      "955: 1321\n",
      "956: 1321\n",
      "957: 1321\n",
      "958: 1321\n",
      "959: 1321\n",
      "960: 1321\n",
      "961: 1321\n",
      "962: 1321\n",
      "963: 1321\n",
      "964: 1321\n",
      "965: 1321\n",
      "966: 1321\n",
      "967: 1321\n",
      "968: 1321\n",
      "969: 1321\n",
      "970: 1321\n",
      "971: 1321\n",
      "972: 1321\n",
      "973: 1321\n",
      "974: 1321\n",
      "975: 1321\n",
      "976: 1321\n",
      "977: 1321\n",
      "978: 1321\n",
      "979: 1321\n",
      "980: 1321\n",
      "981: 1321\n",
      "982: 1321\n",
      "983: 1321\n",
      "984: 1321\n",
      "985: 1321\n",
      "986: 1321\n",
      "987: 1321\n",
      "988: 1321\n",
      "989: 1321\n",
      "990: 1321\n",
      "991: 1321\n",
      "992: 1321\n",
      "993: 1321\n",
      "994: 1321\n",
      "995: 1321\n",
      "996: 1321\n",
      "997: 1321\n",
      "998: 1321\n",
      "999: 1321\n",
      "1000: 1321\n",
      "1001: 1321\n",
      "1002: 1321\n",
      "1003: 1321\n",
      "1004: 1321\n",
      "1005: 1321\n",
      "1006: 1321\n",
      "1007: 1321\n",
      "1008: 1321\n",
      "1009: 1321\n",
      "1010: 1321\n",
      "1011: 1321\n",
      "1012: 1321\n",
      "1013: 1321\n",
      "1014: 1321\n",
      "1015: 1321\n",
      "1016: 1321\n",
      "1017: 1321\n",
      "1018: 1321\n",
      "1019: 1321\n",
      "1020: 1321\n",
      "1021: 1321\n",
      "1022: 1321\n",
      "1023: 1321\n",
      "1024: 1321\n",
      "1025: 1321\n",
      "1026: 1321\n",
      "1027: 1321\n",
      "1028: 1321\n",
      "1029: 1321\n",
      "1030: 1321\n",
      "1031: 1321\n",
      "1032: 1321\n",
      "1033: 1321\n",
      "1034: 1321\n",
      "1035: 1321\n",
      "1036: 1321\n",
      "1037: 1321\n",
      "1038: 1321\n",
      "1039: 1321\n",
      "1040: 1321\n",
      "1041: 1321\n",
      "1042: 1321\n",
      "1043: 1321\n",
      "1044: 1321\n",
      "1045: 1321\n",
      "1046: 1321\n",
      "1047: 1321\n",
      "1048: 1321\n",
      "1049: 1321\n",
      "1050: 1321\n",
      "1051: 1321\n",
      "1052: 1321\n",
      "1053: 1321\n",
      "1054: 1321\n",
      "1055: 1321\n",
      "1056: 1321\n",
      "1057: 1321\n",
      "1058: 1321\n",
      "1059: 1321\n",
      "1060: 1321\n",
      "1061: 1321\n",
      "1062: 1321\n",
      "1063: 1321\n",
      "1064: 1321\n",
      "1065: 1321\n",
      "1066: 1321\n",
      "1067: 1321\n",
      "1068: 1321\n",
      "1069: 1321\n",
      "1070: 1321\n",
      "1071: 1321\n",
      "1072: 1321\n",
      "1073: 1321\n",
      "1074: 1321\n",
      "1075: 1321\n",
      "1076: 1321\n",
      "1077: 1321\n",
      "1078: 1321\n",
      "1079: 1321\n",
      "1080: 1321\n",
      "1081: 1321\n",
      "1082: 1321\n",
      "1083: 1321\n",
      "1084: 1321\n",
      "1085: 1321\n",
      "1086: 1321\n",
      "1087: 1321\n",
      "1088: 1321\n",
      "1089: 1321\n",
      "1090: 1321\n",
      "1091: 1321\n",
      "1092: 1321\n",
      "1093: 1321\n",
      "1094: 1321\n",
      "1095: 1321\n",
      "1096: 1321\n",
      "1097: 1321\n",
      "1098: 1321\n",
      "1099: 1321\n",
      "1100: 1321\n",
      "1101: 1321\n",
      "1102: 1321\n",
      "1103: 1321\n",
      "1104: 1321\n",
      "1105: 1321\n",
      "1106: 1321\n",
      "1107: 1321\n",
      "1108: 1321\n",
      "1109: 1321\n",
      "1110: 1321\n",
      "1111: 1321\n",
      "1112: 1321\n",
      "1113: 1321\n",
      "1114: 1321\n",
      "1115: 1321\n",
      "1116: 1321\n",
      "1117: 1321\n",
      "1118: 1321\n",
      "1119: 1321\n",
      "1120: 1321\n",
      "1121: 1321\n",
      "1122: 1321\n",
      "1123: 1321\n",
      "1124: 1321\n",
      "1125: 1321\n",
      "1126: 1321\n",
      "1127: 1321\n",
      "1128: 1321\n",
      "1129: 1321\n",
      "1130: 1321\n",
      "1131: 1321\n",
      "1132: 1321\n",
      "1133: 1321\n",
      "1134: 1321\n",
      "1135: 1321\n",
      "1136: 1321\n",
      "1137: 1321\n",
      "1138: 1321\n",
      "1139: 1321\n",
      "1140: 1321\n",
      "1141: 1321\n",
      "1142: 1321\n",
      "1143: 1321\n",
      "1144: 1321\n",
      "1145: 1321\n",
      "1146: 1321\n",
      "1147: 1321\n",
      "1148: 1321\n",
      "1149: 1321\n",
      "1150: 1321\n",
      "1151: 1321\n",
      "1152: 1321\n",
      "1153: 1321\n",
      "1154: 1321\n",
      "1155: 1321\n",
      "1156: 1321\n",
      "1157: 1321\n",
      "1158: 1321\n",
      "1159: 1321\n",
      "1160: 1321\n",
      "1161: 1321\n",
      "1162: 1321\n",
      "1163: 1321\n",
      "1164: 1321\n",
      "1165: 1321\n",
      "1166: 1321\n",
      "1167: 1321\n",
      "1168: 1321\n",
      "1169: 1321\n",
      "1170: 1321\n",
      "1171: 1321\n",
      "1172: 1321\n",
      "1173: 1321\n",
      "1174: 1321\n",
      "1175: 1321\n",
      "1176: 1321\n",
      "1177: 1321\n",
      "1178: 1321\n",
      "1179: 1321\n",
      "1180: 1321\n",
      "1181: 1321\n",
      "1182: 1321\n",
      "1183: 1321\n",
      "1184: 1321\n",
      "1185: 1321\n",
      "1186: 1321\n",
      "1187: 1321\n",
      "1188: 1321\n",
      "1189: 1321\n",
      "1190: 1321\n",
      "1191: 1321\n",
      "1192: 1321\n",
      "1193: 1321\n",
      "1194: 1321\n",
      "1195: 1321\n",
      "1196: 1321\n",
      "1197: 1321\n",
      "1198: 1321\n",
      "1199: 1321\n",
      "1200: 1321\n",
      "1201: 1321\n",
      "1202: 1321\n",
      "1203: 1321\n",
      "1204: 1321\n",
      "1205: 1321\n",
      "1206: 1321\n",
      "1207: 1321\n",
      "1208: 1321\n",
      "1209: 1321\n",
      "1210: 1321\n",
      "1211: 1321\n",
      "1212: 1321\n",
      "1213: 1321\n",
      "1214: 1321\n",
      "1215: 1321\n",
      "1216: 1321\n",
      "1217: 1321\n",
      "1218: 1321\n",
      "1219: 1321\n",
      "1220: 1321\n",
      "1221: 1321\n",
      "1222: 1321\n",
      "1223: 1321\n",
      "1224: 1321\n",
      "1225: 1321\n",
      "1226: 1321\n",
      "1227: 1321\n",
      "1228: 1321\n",
      "1229: 1321\n",
      "1230: 1321\n",
      "1231: 1321\n",
      "1232: 1321\n",
      "1233: 1321\n",
      "1234: 1321\n",
      "1235: 1321\n",
      "1236: 1321\n",
      "1237: 1321\n",
      "1238: 1321\n",
      "1239: 1321\n",
      "1240: 1321\n",
      "1241: 1321\n",
      "1242: 1321\n",
      "1243: 1321\n",
      "1244: 1321\n",
      "1245: 1321\n",
      "1246: 1321\n",
      "1247: 1321\n",
      "1248: 1321\n",
      "1249: 1321\n",
      "1250: 1321\n",
      "1251: 1321\n",
      "1252: 1321\n",
      "1253: 1321\n",
      "1254: 1321\n",
      "1255: 1321\n",
      "1256: 1321\n",
      "1257: 1321\n",
      "1258: 1321\n",
      "1259: 1321\n",
      "1260: 1321\n",
      "1261: 1321\n",
      "1262: 1321\n",
      "1263: 1321\n",
      "1264: 1321\n",
      "1265: 1321\n",
      "1266: 1321\n",
      "1267: 1321\n",
      "1268: 1321\n",
      "1269: 1321\n",
      "1270: 1321\n",
      "1271: 1321\n",
      "1272: 1321\n",
      "1273: 1321\n",
      "1274: 1321\n",
      "1275: 1321\n",
      "1276: 1321\n",
      "1277: 1321\n",
      "1278: 1321\n",
      "1279: 1321\n",
      "1280: 1321\n",
      "1281: 1321\n",
      "1282: 1321\n",
      "1283: 1321\n",
      "1284: 1321\n",
      "1285: 1321\n",
      "1286: 1321\n",
      "1287: 1321\n",
      "1288: 1321\n",
      "1289: 1321\n",
      "1290: 1321\n",
      "1291: 1321\n",
      "1292: 1321\n",
      "1293: 1321\n",
      "1294: 1321\n",
      "1295: 1321\n",
      "1296: 1321\n",
      "1297: 1321\n",
      "1298: 1321\n",
      "1299: 1321\n",
      "1300: 1321\n",
      "1301: 1321\n",
      "1302: 1321\n",
      "1303: 1321\n",
      "1304: 1321\n",
      "1305: 1321\n",
      "1306: 1321\n",
      "1307: 1321\n",
      "1308: 1321\n",
      "1309: 1321\n",
      "1310: 1321\n",
      "1311: 1321\n",
      "1312: 1321\n",
      "1313: 1321\n",
      "1314: 1321\n",
      "1315: 1321\n",
      "1316: 1321\n",
      "1317: 1321\n",
      "1318: 1321\n",
      "1319: 1321\n",
      "1320: 1321\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(f\"{idx}: {len(df)}\")\n",
    "    text = row['echoInput']\n",
    "\n",
    "    out = inference_model(model, tokenizer, config_dict, text)\n",
    "    out = out.replace(text, '')\n",
    "    out = out.replace(\"Therapist: \", '')\n",
    "    out = out.replace(\"\\n\", '')\n",
    "    #print(out)\n",
    "    \n",
    "    #if idx == 50: break\n",
    "    df.loc[idx, 'echoReflection'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6954acc9-3924-47fe-9af1-292b9011e157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PromptAndResponse</th>\n",
       "      <th>instruction</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>alphaInput</th>\n",
       "      <th>betaInput</th>\n",
       "      <th>charlieInput</th>\n",
       "      <th>deltaInput</th>\n",
       "      <th>echoInput</th>\n",
       "      <th>alphaReflection</th>\n",
       "      <th>betaReflection</th>\n",
       "      <th>charlieReflection</th>\n",
       "      <th>deltaReflection</th>\n",
       "      <th>echoReflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOT: What will it look like when you have made...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>well, i think , ill leave the addiction progr...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: What will it look like when you hav...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:The following is an interactio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOT: What will it look like when you have made...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>weird but healthier</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: What will it look like when you hav...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>It seems that the change in your smoking habit...</td>\n",
       "      <td>It seems that you are uncertain about the heal...</td>\n",
       "      <td>It seems that you believe making changes to yo...</td>\n",
       "      <td>It sounds like you believe that making this ch...</td>\n",
       "      <td>It sounds like you're not sure what making a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOT: What will it look like when you have made...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>unfortunately, I can't imagine that</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: What will it look like when you hav...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>It seems that you're currently experiencing di...</td>\n",
       "      <td>It seems that you're uncertain about how this ...</td>\n",
       "      <td>It seems that you're uncertain about what the ...</td>\n",
       "      <td>It seems that you are uncertain about how the ...</td>\n",
       "      <td>It seems that you're uncertain about how the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOT: What will it look like when you have made...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>the same, as I do not desire a change</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: What will it look like when you hav...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>You feel that things will essentially remain t...</td>\n",
       "      <td>You feel that there won't be any significant o...</td>\n",
       "      <td>You feel that making a change in your smoking ...</td>\n",
       "      <td>You feel that there won't be any noticeable di...</td>\n",
       "      <td>It sounds like you're not interested in changi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOT: What will it look like when you have made...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>What will it look like when you have made this...</td>\n",
       "      <td>the same</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: What will it look like when you hav...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>So, you feel as though there won't be any noti...</td>\n",
       "      <td>You feel that things will essentially remain t...</td>\n",
       "      <td>It seems that you feel there won't be any noti...</td>\n",
       "      <td>You feel that things will essentially remain t...</td>\n",
       "      <td>You feel that things will essentially remain t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>BOT: Finally, what are the steps you need to t...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>Finally, what are the steps you need to take t...</td>\n",
       "      <td>At the beginning, I try to get off the dose of...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: Finally, what are the steps you nee...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>It sounds like you're planning to at the begin...</td>\n",
       "      <td>It sounds like you're planning to avoid the ha...</td>\n",
       "      <td>It sounds like you're planning to leave the nu...</td>\n",
       "      <td>You plan to start by reducing the number of ci...</td>\n",
       "      <td>It sounds like you're considering exploring al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>BOT: Finally, what are the steps you need to t...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>Finally, what are the steps you need to take t...</td>\n",
       "      <td>Actually just to do it</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: Finally, what are the steps you nee...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>It sounds like you're ready to take action and...</td>\n",
       "      <td>You just need to be ready to begin this change...</td>\n",
       "      <td>It sounds like you're ready to take action and...</td>\n",
       "      <td>It sounds like you're ready to take action and...</td>\n",
       "      <td>It sounds like you're truly determined to quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>BOT: Finally, what are the steps you need to t...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>Finally, what are the steps you need to take t...</td>\n",
       "      <td>Absolutely no steps</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: Finally, what are the steps you nee...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>You don't have any specific steps in mind for ...</td>\n",
       "      <td>You recognize that fully committing to the pla...</td>\n",
       "      <td>You recognize that none of the steps are neces...</td>\n",
       "      <td>You are fully certain about the necessary step...</td>\n",
       "      <td>You don't have any specific steps in mind for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>BOT: Finally, what are the steps you need to t...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>Finally, what are the steps you need to take t...</td>\n",
       "      <td>1. Don't buy cigarettes. 2. smoke less</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: Finally, what are the steps you nee...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>You plan to stop purchasing cigarettes as a st...</td>\n",
       "      <td>You plan to reduce your cigarette consumption ...</td>\n",
       "      <td>You plan to reduce the cost of cigarettes and ...</td>\n",
       "      <td>You are determined to stop purchasing cigarett...</td>\n",
       "      <td>You plan to stop purchasing cigarettes as a st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>BOT: Finally, what are the steps you need to t...</td>\n",
       "      <td>The following is an interaction between a ther...</td>\n",
       "      <td>Finally, what are the steps you need to take t...</td>\n",
       "      <td>\\nI have to have the strength to change and st...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>Therapist: Finally, what are the steps you nee...</td>\n",
       "      <td>Instruction: The following is an interaction b...</td>\n",
       "      <td>instruction: The following is an interaction b...</td>\n",
       "      <td>### Instruction:\\nThe following is an interact...</td>\n",
       "      <td>It sounds like you believe in your ability to ...</td>\n",
       "      <td>It sounds like you believe that focusing on re...</td>\n",
       "      <td>It sounds like you're ready to take small step...</td>\n",
       "      <td>It sounds like you're seeking the greater stre...</td>\n",
       "      <td>It sounds like you believe that taking small s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1321 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      PromptAndResponse  \\\n",
       "0     BOT: What will it look like when you have made...   \n",
       "1     BOT: What will it look like when you have made...   \n",
       "2     BOT: What will it look like when you have made...   \n",
       "3     BOT: What will it look like when you have made...   \n",
       "4     BOT: What will it look like when you have made...   \n",
       "...                                                 ...   \n",
       "1316  BOT: Finally, what are the steps you need to t...   \n",
       "1317  BOT: Finally, what are the steps you need to t...   \n",
       "1318  BOT: Finally, what are the steps you need to t...   \n",
       "1319  BOT: Finally, what are the steps you need to t...   \n",
       "1320  BOT: Finally, what are the steps you need to t...   \n",
       "\n",
       "                                            instruction  \\\n",
       "0     The following is an interaction between a ther...   \n",
       "1     The following is an interaction between a ther...   \n",
       "2     The following is an interaction between a ther...   \n",
       "3     The following is an interaction between a ther...   \n",
       "4     The following is an interaction between a ther...   \n",
       "...                                                 ...   \n",
       "1316  The following is an interaction between a ther...   \n",
       "1317  The following is an interaction between a ther...   \n",
       "1318  The following is an interaction between a ther...   \n",
       "1319  The following is an interaction between a ther...   \n",
       "1320  The following is an interaction between a ther...   \n",
       "\n",
       "                                               question  \\\n",
       "0     What will it look like when you have made this...   \n",
       "1     What will it look like when you have made this...   \n",
       "2     What will it look like when you have made this...   \n",
       "3     What will it look like when you have made this...   \n",
       "4     What will it look like when you have made this...   \n",
       "...                                                 ...   \n",
       "1316  Finally, what are the steps you need to take t...   \n",
       "1317  Finally, what are the steps you need to take t...   \n",
       "1318  Finally, what are the steps you need to take t...   \n",
       "1319  Finally, what are the steps you need to take t...   \n",
       "1320  Finally, what are the steps you need to take t...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     well, i think , ill leave the addiction progr...   \n",
       "1                                   weird but healthier   \n",
       "2                   unfortunately, I can't imagine that   \n",
       "3                 the same, as I do not desire a change   \n",
       "4                                              the same   \n",
       "...                                                 ...   \n",
       "1316  At the beginning, I try to get off the dose of...   \n",
       "1317                             Actually just to do it   \n",
       "1318                                Absolutely no steps   \n",
       "1319             1. Don't buy cigarettes. 2. smoke less   \n",
       "1320  \\nI have to have the strength to change and st...   \n",
       "\n",
       "                                             alphaInput  \\\n",
       "0     Instruction: The following is an interaction b...   \n",
       "1     Instruction: The following is an interaction b...   \n",
       "2     Instruction: The following is an interaction b...   \n",
       "3     Instruction: The following is an interaction b...   \n",
       "4     Instruction: The following is an interaction b...   \n",
       "...                                                 ...   \n",
       "1316  Instruction: The following is an interaction b...   \n",
       "1317  Instruction: The following is an interaction b...   \n",
       "1318  Instruction: The following is an interaction b...   \n",
       "1319  Instruction: The following is an interaction b...   \n",
       "1320  Instruction: The following is an interaction b...   \n",
       "\n",
       "                                              betaInput  \\\n",
       "0     Therapist: What will it look like when you hav...   \n",
       "1     Therapist: What will it look like when you hav...   \n",
       "2     Therapist: What will it look like when you hav...   \n",
       "3     Therapist: What will it look like when you hav...   \n",
       "4     Therapist: What will it look like when you hav...   \n",
       "...                                                 ...   \n",
       "1316  Therapist: Finally, what are the steps you nee...   \n",
       "1317  Therapist: Finally, what are the steps you nee...   \n",
       "1318  Therapist: Finally, what are the steps you nee...   \n",
       "1319  Therapist: Finally, what are the steps you nee...   \n",
       "1320  Therapist: Finally, what are the steps you nee...   \n",
       "\n",
       "                                           charlieInput  \\\n",
       "0     Instruction: The following is an interaction b...   \n",
       "1     Instruction: The following is an interaction b...   \n",
       "2     Instruction: The following is an interaction b...   \n",
       "3     Instruction: The following is an interaction b...   \n",
       "4     Instruction: The following is an interaction b...   \n",
       "...                                                 ...   \n",
       "1316  Instruction: The following is an interaction b...   \n",
       "1317  Instruction: The following is an interaction b...   \n",
       "1318  Instruction: The following is an interaction b...   \n",
       "1319  Instruction: The following is an interaction b...   \n",
       "1320  Instruction: The following is an interaction b...   \n",
       "\n",
       "                                             deltaInput  \\\n",
       "0     instruction: The following is an interaction b...   \n",
       "1     instruction: The following is an interaction b...   \n",
       "2     instruction: The following is an interaction b...   \n",
       "3     instruction: The following is an interaction b...   \n",
       "4     instruction: The following is an interaction b...   \n",
       "...                                                 ...   \n",
       "1316  instruction: The following is an interaction b...   \n",
       "1317  instruction: The following is an interaction b...   \n",
       "1318  instruction: The following is an interaction b...   \n",
       "1319  instruction: The following is an interaction b...   \n",
       "1320  instruction: The following is an interaction b...   \n",
       "\n",
       "                                              echoInput  \\\n",
       "0     ### Instruction:\\nThe following is an interact...   \n",
       "1     ### Instruction:\\nThe following is an interact...   \n",
       "2     ### Instruction:\\nThe following is an interact...   \n",
       "3     ### Instruction:\\nThe following is an interact...   \n",
       "4     ### Instruction:\\nThe following is an interact...   \n",
       "...                                                 ...   \n",
       "1316  ### Instruction:\\nThe following is an interact...   \n",
       "1317  ### Instruction:\\nThe following is an interact...   \n",
       "1318  ### Instruction:\\nThe following is an interact...   \n",
       "1319  ### Instruction:\\nThe following is an interact...   \n",
       "1320  ### Instruction:\\nThe following is an interact...   \n",
       "\n",
       "                                        alphaReflection  \\\n",
       "0     Instruction: The following is an interaction b...   \n",
       "1     It seems that the change in your smoking habit...   \n",
       "2     It seems that you're currently experiencing di...   \n",
       "3     You feel that things will essentially remain t...   \n",
       "4     So, you feel as though there won't be any noti...   \n",
       "...                                                 ...   \n",
       "1316  It sounds like you're planning to at the begin...   \n",
       "1317  It sounds like you're ready to take action and...   \n",
       "1318  You don't have any specific steps in mind for ...   \n",
       "1319  You plan to stop purchasing cigarettes as a st...   \n",
       "1320  It sounds like you believe in your ability to ...   \n",
       "\n",
       "                                         betaReflection  \\\n",
       "0     What will it look like when you have made this...   \n",
       "1     It seems that you are uncertain about the heal...   \n",
       "2     It seems that you're uncertain about how this ...   \n",
       "3     You feel that there won't be any significant o...   \n",
       "4     You feel that things will essentially remain t...   \n",
       "...                                                 ...   \n",
       "1316  It sounds like you're planning to avoid the ha...   \n",
       "1317  You just need to be ready to begin this change...   \n",
       "1318  You recognize that fully committing to the pla...   \n",
       "1319  You plan to reduce your cigarette consumption ...   \n",
       "1320  It sounds like you believe that focusing on re...   \n",
       "\n",
       "                                      charlieReflection  \\\n",
       "0     Instruction: The following is an interaction b...   \n",
       "1     It seems that you believe making changes to yo...   \n",
       "2     It seems that you're uncertain about what the ...   \n",
       "3     You feel that making a change in your smoking ...   \n",
       "4     It seems that you feel there won't be any noti...   \n",
       "...                                                 ...   \n",
       "1316  It sounds like you're planning to leave the nu...   \n",
       "1317  It sounds like you're ready to take action and...   \n",
       "1318  You recognize that none of the steps are neces...   \n",
       "1319  You plan to reduce the cost of cigarettes and ...   \n",
       "1320  It sounds like you're ready to take small step...   \n",
       "\n",
       "                                        deltaReflection  \\\n",
       "0     instruction: The following is an interaction b...   \n",
       "1     It sounds like you believe that making this ch...   \n",
       "2     It seems that you are uncertain about how the ...   \n",
       "3     You feel that there won't be any noticeable di...   \n",
       "4     You feel that things will essentially remain t...   \n",
       "...                                                 ...   \n",
       "1316  You plan to start by reducing the number of ci...   \n",
       "1317  It sounds like you're ready to take action and...   \n",
       "1318  You are fully certain about the necessary step...   \n",
       "1319  You are determined to stop purchasing cigarett...   \n",
       "1320  It sounds like you're seeking the greater stre...   \n",
       "\n",
       "                                         echoReflection  \n",
       "0     ### Instruction:The following is an interactio...  \n",
       "1     It sounds like you're not sure what making a c...  \n",
       "2     It seems that you're uncertain about how the c...  \n",
       "3     It sounds like you're not interested in changi...  \n",
       "4     You feel that things will essentially remain t...  \n",
       "...                                                 ...  \n",
       "1316  It sounds like you're considering exploring al...  \n",
       "1317  It sounds like you're truly determined to quit...  \n",
       "1318  You don't have any specific steps in mind for ...  \n",
       "1319  You plan to stop purchasing cigarettes as a st...  \n",
       "1320  It sounds like you believe that taking small s...  \n",
       "\n",
       "[1321 rows x 14 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bef6935-be9a-4d1b-879d-67051feeac79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"ABC is a startup based in New York City and Paris\"\n",
    "\n",
    "# encode the input text into tokens using the tokenizer\n",
    "tokenized_text = tokenizer.encode(\n",
    "    text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "encodings_dict = tokenizer(text, truncation=True, max_length=256, padding=\"max_length\")\n",
    "input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "input_ids = tokenized_text.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d7ef68-e635-4427-a961-dbdc4a90bda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encodings_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2950/680839160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencodings_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encodings_dict' is not defined"
     ]
    }
   ],
   "source": [
    "encodings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadd92a0-908a-4559-b364-89c637ab58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2428e+08, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():   \n",
    "    loss = model(input_ids = input_ids, labels = input_ids).loss\n",
    "ppl = torch.exp(loss)\n",
    "print(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46d32a40-9c1a-41b4-8b14-74a9da4d29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2428e+08)\n",
      "tensor(8.8227e+08)\n",
      "tensor(1.)\n",
      "tensor(7.0527e+09)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"ABC is a startup based in New York City and Paris\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss).detach()\n",
    "print(ppl)\n",
    "\n",
    "\n",
    "inputs_wiki_text = tokenizer(\"Generative Pretrained Transformer is an opensource artificial intelligence created by OpenAI in February 2019\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss).detach()\n",
    "print(ppl)\n",
    "\n",
    "inputs_wiki_text = tokenizer(\"Instruction\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss).detach()\n",
    "print(ppl)\n",
    "\n",
    "inputs_wiki_text = tokenizer(\"RABBA RABBA RABBA\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss).detach()\n",
    "print(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0a459a0-4db6-4d12-bcbd-cdcfb7e88f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25807324-772c-47cf-b711-bf0f00d2f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca1aa9-7afb-47b9-ab1e-ddefdbd8d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1c150-b716-4af8-b3f9-c62164bbd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = model.config.n_positions\n",
    "stride = 512\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "    end_loc = min(begin_loc + max_length, seq_len)\n",
    "    trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "        # to the left by 1.\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "    prev_end_loc = end_loc\n",
    "    if end_loc == seq_len:\n",
    "        break\n",
    "\n",
    "ppl = torch.exp(torch.stack(nlls).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
