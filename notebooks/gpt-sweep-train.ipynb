{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c6622e2-24df-40eb-ad1b-01823c25f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# wandb for tracking experiment and sweeping hyperparamters\n",
    "import wandb\n",
    "# pyyaml (yaml) :: parses configuration files (YAML files)\n",
    "# see https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started for more information on YAML files\n",
    "import yaml \n",
    "\n",
    "# huggingface :: datasets : dataset-handling libraries from huggingface\n",
    "from datasets import load_dataset\n",
    "#from datasets.filesystems import S3FileSystem # for S3 interactions\n",
    "\n",
    "# huggingface :: transformers : transformer, trainer and tokenizer objects for the actual training\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027eaab0-abc3-4cec-b375-d5bdf2245067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk punkt sentence tokenizer, divides text into a list of sentences\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bef5de79-8cc4-4b63-b5d5-a2bb874ea8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 21 18:08:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   26C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39ab29e4-3481-4eb7-9170-bfb13c36509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-refl-21-feb-2023.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59a9d478-d8e4-45c9-b8e0-51be9d07d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-refl-19-feb-2023.yaml\"\n",
    "# open yaml config as a strema and load into config_dict\n",
    "with open(path_to_config, \"r\") as stream:\n",
    "    try:\n",
    "        config_dict = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Configuration load failed!\")\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607b596e-762a-4735-a413-00f094c030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_dict[\"data_train_path\"])\n",
    "df_val = pd.read_csv(config_dict[\"data_validation_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46f7a90-2ddc-4d32-9b54-de380dcfb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # drop NA values\n",
    "triplets = df.triplet.copy()  # copy over triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc0eea85-8da6-4337-8aca-e8945c78c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_triplets = df_val.triplet.copy()  # validation triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "839c2a2e-7c5c-4031-9a15-a929c4e3cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f416c34a290>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how long is our training data?\n",
    "doc_lengths = []\n",
    "for triplet in triplets:\n",
    "    tokens = nltk.word_tokenize(triplet)\n",
    "    doc_lengths.append(len(tokens))\n",
    "doc_lengths = np.asarray(doc_lengths)\n",
    "sns.displot(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be28cbd-b469-486c-94a1-1b8fb23540cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.57807308970099"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(doc_lengths)\n",
    "# on average, we have ~47.5 tokens per entry, a good thing for GPT2 embedding size of 768 in gpt-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b47867b6-71cb-4cea-b2ab-b7e95ccff6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the below set the corresponding values from the configuration file config.yaml:\n",
    "model_name = config_dict[\"model_name\"]\n",
    "pretrained = config_dict[\"pretrained\"]\n",
    "data_train_path = config_dict[\"data_train_path\"]\n",
    "data_validation_path = config_dict[\"data_validation_path\"]\n",
    "\n",
    "\n",
    "\n",
    "output_data_dir = config_dict[\"output_data_dir\"] + \"/\"\n",
    "output_model_dir = config_dict[\"output_model_dir\"] + \"/\"\n",
    "\n",
    "hyperparameters = config_dict[\"training_settings\"][\"hyperparameters\"]\n",
    "hyperparameters[\"learning_rate\"] = float(hyperparameters[\"learning_rate\"])\n",
    "hyperparameters[\"weight_decay\"] = float(hyperparameters[\"weight_decay\"])\n",
    "\n",
    "deepspeed_config = config_dict[\"training_settings\"][\"deepspeed_settings\"]\n",
    "\n",
    "learning_rate = hyperparameters['learning_rate']\n",
    "epsilon = float(hyperparameters['epsilon'])  # epsilon must be a float, not str\n",
    "epochs = hyperparameters['epochs']\n",
    "warmup_steps = float(hyperparameters['warmup_steps'])\n",
    "sample_every = float(hyperparameters['sample_every'])\n",
    "batch_size = int(hyperparameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04be7ade-4c30-415d-b9c9-c4efe4dc6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load gpt-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2bdd305-2a1e-43bf-85f4-c1379d111765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|startoftext|> token has the id 50257\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The padding token <|pad|> has the id 50258\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "074cb295-abc7-404d-9674-2f751e9863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of examples passed through model before a backwards pass\n",
    "batch_size = hyperparameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b4ddb39-4b65-475d-aa7d-89d28ffa7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    # Inherits Dataset from PyTorch, a data primitive which\n",
    "    # stores samples and corresponding labels\n",
    "    # custom Dataset needs init, len, and getitem\n",
    "    # init runs once when instantiating Dataset object\n",
    "    def __init__(self, txt_list, tokenzier, gpt2_type='gpt2', max_length=768):\n",
    "        self.tokenizer = tokenizer,\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        # for each text list, encode it using tokenizer then unpacl encodings dict into:\n",
    "        # input_ids: numerical representations of our tokens\n",
    "        # attn_masks: indicates which tokens should be attended to (and which are pads)\n",
    "        for txt in txt_list:\n",
    "            # tokenize the txt with a custom start and end token\n",
    "            # encodings dict contains both our token input ids and attention mask\n",
    "            # truncation will clip sentences that are too long\n",
    "            # padding adds pad tokens until we reach max input sentence length 768\n",
    "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            \n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    # overrides len() to returns the number of samples in our dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    # loads and returns a sample from dataset at given index idx\n",
    "    # sometimes we need to do type swapping in getitem, but not here\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "            \n",
    "        \n",
    "train_dataset = GPT2Dataset(triplets, tokenizer, max_length=768)\n",
    "val_dataset = GPT2Dataset(val_triplets, tokenizer, max_length=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17faab74-1b68-468e-bb7c-4b58bc6b93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2Dataset(triplets, tokenizer, max_length=768)\n",
    "val_dataset = GPT2Dataset(val_triplets, tokenizer, max_length=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e12d8e-66c1-47db-91a0-c3473a54f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 Training Samples\n",
      "34 Validation Samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_dataset)} Training Samples\")\n",
    "print(f\"{len(val_dataset)} Validation Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93400af7-95fd-4fea-af61-db8d864d0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and validation datasets\n",
    "# PyTorch DataLoaders wrap iterable around a Dataset to access samples easily\n",
    "# We typically pass in minibatches and reshuffle data at epochs to reduce overfitting\n",
    "# DataLoaders leverage python's multiprocessing to speed up data retrieval\n",
    "\n",
    "# take training samples in random order\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "# For validation, the order doesn't matter, so we read sequentially\n",
    "validation_dataloader = DataLoader(val_dataset,\n",
    "                                   sampler=SequentialSampler(val_dataset),\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab14844a-0bee-425d-9036-8b9e93c43f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to instantiate model\n",
    "configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f2b34ca-76bd-4c8d-a2fa-820003e6efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ffedcee-b6c7-43d8-b622-68527843efb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embeddings for our custom tokens (e.g. bos_token)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9dd3b69-eaea-4e7e-8de3-1d58a81ec9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ae74060-8628-4706-b597-14b2d8597a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sends model to current device - in this case CUDA\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5dc18a1-03e3-4c02-8d84-6e05af269bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value\n",
    "seed_val = int(hyperparameters['seed'])\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f7befc2-c1be-4193-9a26-79debc388bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewbrown\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "time=\"2023-02-21T18:14:05Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230221_181404-09pk3p2g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/09pk3p2g\" target=\"_blank\">jumping-surf-20</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/09pk3p2g\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/09pk3p2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/09pk3p2g?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4168363450>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"gpt2-sweep-reflector\",\n",
    "  notes=\"Trying to sweep gpt2 reflector\",\n",
    "  tags=[\"gpt2\", \"reflector\", \"sweep\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e37c038-3708-4c95-97d6-74f362438bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'find_hyperparams_automatically': False,\n",
       " 'num_trials': 10,\n",
       " 'fp16': True,\n",
       " 'deepspeed': True,\n",
       " 'grad_accumulation_steps': 2,\n",
       " 'eval_batch_size': 1,\n",
       " 'learning_rate': 0.0002,\n",
       " 'epochs': 20,\n",
       " 'warmup_steps': '1e2',\n",
       " 'epsilon': '3e-8',\n",
       " 'batch_size': 1,\n",
       " 'sample_every': 100,\n",
       " 'seed': 42,\n",
       " 'eval_steps': 10,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab210284-b099-4bed-bdd5-63a2fcf5bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4590f1bd-04a3-42a7-974e-8d94530b2feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c625280e-dc33-4659-a9f6-049fafc486a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total num training steps is [num batches] x [num epochs]\n",
    "# (not the same number as num training sample)\n",
    "total_steps = len(train_dataloader) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38367cca-ce12-4eb0-bebc-81ebccc4bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate scheduler\n",
    "# we schedule learning rate using \n",
    "# optimzer, num_warmup steps, and num_training steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdba5811-ed9e-4393-94d7-94ee67da836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53c41e7c-1f89-4bd7-a0d8-88f53e7c87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'name': 'gpt2-xl Grid Sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'train_acc'},\n",
    "    \n",
    "    # parameters is the nested dictionary of hyperparameters we are sweeping\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [1]},\n",
    "        'epochs': {'values': [5, 10, 15]},\n",
    "        'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1},\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b3cc521f-693e-452a-84ed-0cff6f0ee7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 3n2rw2r6\n",
      "Sweep URL: https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"gpt2-sweep-reflector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c54b1ab-0234-4a0f-8330-959d07ca9b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2023-02-20T04:23:01Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_042301-r2kfyqs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/r2kfyqs6\" target=\"_blank\">misunderstood-rain-12</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/r2kfyqs6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/r2kfyqs6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/r2kfyqs6?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6a4432c610>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"gpt2-sweep-reflector\",\n",
    "  config=config_dict,\n",
    "  notes=\"Trying to sweep gpt2 reflector\",\n",
    "  tags=[\"gpt2\", \"reflector\", \"sweep\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ccd88d87-d526-4edc-bb72-dafdf4811c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    # Inherits Dataset from PyTorch, a data primitive which\n",
    "    # stores samples and corresponding labels\n",
    "    # custom Dataset needs init, len, and getitem\n",
    "    # init runs once when instantiating Dataset object\n",
    "    def __init__(self, txt_list, tokenzier, gpt2_type='gpt2', max_length=768):\n",
    "        self.tokenizer = tokenizer,\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        # for each text list, encode it using tokenizer then unpacl encodings dict into:\n",
    "        # input_ids: numerical representations of our tokens\n",
    "        # attn_masks: indicates which tokens should be attended to (and which are pads)\n",
    "        for txt in txt_list:\n",
    "            # tokenize the txt with a custom start and end token\n",
    "            # encodings dict contains both our token input ids and attention mask\n",
    "            # truncation will clip sentences that are too long\n",
    "            # padding adds pad tokens until we reach max input sentence length 768\n",
    "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            \n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    # overrides len() to returns the number of samples in our dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    # loads and returns a sample from dataset at given index idx\n",
    "    # sometimes we need to do type swapping in getitem, but not here\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "            \n",
    "def build_dataset(triplets, tokenizer, batch_size, max_length=768):\n",
    "    dataset = GPT2Dataset(triplets, tokenizer, max_length=768)\n",
    "    return DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53d1f543-ed25-4df4-9988-a387ff05cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "def build_optimizer(model, learning_rate, epsilon):\n",
    "    return AdamW(model.parameters(), lr = learning_rate, eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8643bc2d-72cc-4ec3-ad7b-be249af0bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    path_to_config = \"../configs/gpt2-refl-19-feb-2023.yaml\"\n",
    "    # open yaml config as a strema and load into config_dict\n",
    "    with open(path_to_config, \"r\") as stream:\n",
    "        try:\n",
    "            config_dict = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(\"Configuration load failed!\")\n",
    "            print(exc)\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(project=\"gpt2-sweep-reflector\", config=config_dict, notes=\"Trying to sweep gpt2 reflector\",tags=[\"gpt2\", \"reflector\", \"sweep\"]):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        batch_size = int(config.training_settings['hyperparameters']['batch_size'])\n",
    "        learning_rate = float(config.training_settings['hyperparameters']['learning_rate'])\n",
    "        epsilon = float(config.training_settings['hyperparameters']['epsilon'])\n",
    "        epochs = int(config.training_settings['hyperparameters']['epochs'])\n",
    "\n",
    "        loader = build_dataset(triplets, tokenizer, batch_size, max_length=768)\n",
    "        # not varying model architecture\n",
    "        #network = build_network(config.fc_layer_size, config.dropout)\n",
    "        optimizer = build_optimizer(model, learning_rate, epsilon)\n",
    "        for epoch in range(epochs):\n",
    "            avg_loss = train_epoch(model, loader, optimizer)\n",
    "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a36bfbbf-4cf5-4df5-8e38-3f0c7380b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wnyy3e9u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03908492653710586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "time=\"2023-02-20T04:27:18Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_042717-wnyy3e9u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/wnyy3e9u\" target=\"_blank\">icy-sweep-4</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/wnyy3e9u\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/wnyy3e9u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:14 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:14 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:14 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.01397</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-4</strong> at: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/wnyy3e9u\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/wnyy3e9u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230220_042717-wnyy3e9u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rz26rorc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002138355664066671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "time=\"2023-02-20T04:53:23Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_045322-rz26rorc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/rz26rorc\" target=\"_blank\">autumn-sweep-5</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/rz26rorc\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/rz26rorc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:15 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:22 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:16 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.0089</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-5</strong> at: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/rz26rorc\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/rz26rorc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230220_045322-rz26rorc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mpxfhf28 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07716695180056597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "time=\"2023-02-20T05:19:24Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_051923-mpxfhf28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/mpxfhf28\" target=\"_blank\">upbeat-sweep-6</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/mpxfhf28\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/mpxfhf28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:17 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:23 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:25 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:24 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:22 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:18 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.0112</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-6</strong> at: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/mpxfhf28\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/mpxfhf28</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230220_051923-mpxfhf28/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4kmtoa5b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.016577142569395877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "time=\"2023-02-20T05:46:09Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_054608-4kmtoa5b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/4kmtoa5b\" target=\"_blank\">hardy-sweep-1</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/4kmtoa5b\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/4kmtoa5b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:23 ---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:22 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:25 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:26 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.01033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-1</strong> at: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/4kmtoa5b\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/4kmtoa5b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230220_054608-4kmtoa5b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zqi6lxsu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04532143387048465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "time=\"2023-02-20T06:14:40Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230220_061439-zqi6lxsu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/zqi6lxsu\" target=\"_blank\">revived-sweep-2</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/sweeps/3n2rw2r6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/zqi6lxsu\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/zqi6lxsu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:22 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:19 ---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:20 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:21 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:23 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:28 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:28 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:27 ---\n",
      "---Training...---\n",
      "---Done Training Epoch!---\n",
      "---Training epoch took 0:01:28 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.00989</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-sweep-2</strong> at: <a href=\"https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/zqi6lxsu\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-sweep-reflector/runs/zqi6lxsu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230220_061439-zqi6lxsu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "480425a6-7850-460f-b6e6-3f8ea1d06716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, optimizer):\n",
    "    training_stats = []\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    \"\"\"\n",
    "    Training for one epoch\n",
    "    \"\"\"\n",
    "    wandb.watch(model)\n",
    "    print(\"---Training...---\")\n",
    "\n",
    "    # start epoch timer\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # sets model into train mode, not actual backprop\n",
    "    # dropout and batchnorm behave differently\n",
    "    # opposite of model.eval() for inference mode\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # grab input tokens, labels, and masks\n",
    "        input_tokens = batch[0].to(device)\n",
    "        # in this case, we're generating text,\n",
    "        # so label tokens are the input tokens shifted\n",
    "        label_tokens = batch[0].to(device)\n",
    "        attn_masks = batch[1].to(device)\n",
    "\n",
    "        # clear any gradients from model tensors\n",
    "        # prevents any gradient accumulation\n",
    "        model.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(input_tokens,\n",
    "                        labels=label_tokens,\n",
    "                        attention_mask=attn_masks,\n",
    "                        token_type_ids=None\n",
    "                       )\n",
    "\n",
    "        # grab loss from outputs\n",
    "        loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()  # detach from device with item\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # backpropagation step\n",
    "        # computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # updates gradient values\n",
    "        # x.grad += dloss/dx\n",
    "        loss.backward()\n",
    "\n",
    "        # step optimizer\n",
    "        # updates the value of x using the gradient x.grad\n",
    "        # x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "\n",
    "        # step scheduler\n",
    "        # tells scheduler to increase learning rate\n",
    "        # using our warmup steps\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"---Done Training Epoch!---\")\n",
    "    # measure how long the epoch took\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(f\"---Training epoch took {training_time} ---\")\n",
    "    # calculate average loss over all batches\n",
    "    return total_train_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ae0d5-cb1e-4eb6-8581-15604e39fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    print(\"---Running Validation...---\")\n",
    "    \n",
    "    # start batch timer\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # set model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    # evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # grab input tokens, labels, and masks\n",
    "        input_tokens = batch[0].to(device)\n",
    "        # in this case, we're generating text,\n",
    "        # so label tokens are the input tokens shifted\n",
    "        label_tokens = batch[0].to(device)\n",
    "        attn_masks = batch[1].to(device)\n",
    "        \n",
    "        # freeze gradients\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tokens,\n",
    "                            attention_mask=attn_masks,\n",
    "                            labels=label_tokens)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss\n",
    "        \n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "    print(f\"Validation took: {validation_time}\")\n",
    "    \n",
    "    # save all training statistics from the epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        })\n",
    "    # log training data to wandb as well\n",
    "    wandb.log({\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f16de48c-372a-461e-92d2-0f87b15aee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0:01:08</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0:01:10</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0:01:13</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0:01:21</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0:01:23</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Validation Loss Training Time Validation Time\n",
       "epoch                                                              \n",
       "1               0.05             0.09       0:01:08         0:00:02\n",
       "2               0.05             0.09       0:01:10         0:00:03\n",
       "3               0.05             0.09       0:01:13         0:00:03\n",
       "4               0.05             0.09       0:01:21         0:00:03\n",
       "5               0.05             0.09       0:01:23         0:00:03"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3929adad-19ed-40fd-890d-5f69b669aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Validation Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6c00054-512d-468f-bad7-c22d66e527b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPT-2 model has 148 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "transformer.wte.weight                                  (50259, 768)\n",
      "transformer.wpe.weight                                   (1024, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "transformer.h.0.ln_1.weight                                   (768,)\n",
      "transformer.h.0.ln_1.bias                                     (768,)\n",
      "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
      "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
      "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
      "transformer.h.0.attn.c_proj.bias                              (768,)\n",
      "transformer.h.0.ln_2.weight                                   (768,)\n",
      "transformer.h.0.ln_2.bias                                     (768,)\n",
      "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
      "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
      "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
      "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "transformer.ln_f.weight                                       (768,)\n",
      "transformer.ln_f.bias                                         (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:2]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[2:14]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5689d6a-934e-440e-906d-4325212bec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../../Output/model/gpt-feb5/\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the finetuned model\n",
    "output_dir = '../../Output/model/gpt-feb6/'\n",
    "tokenizer_dir = '../../Output/model/gpt-tokenizer-feb6/'\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(tokenizer_dir):\n",
    "    os.makedirs(tokenizer_dir)\n",
    "    \n",
    "    \n",
    "print(f\"Saving model to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ded92b74-16ff-4894-8fb4-a1fa20e7e76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../Output/model/gpt-tokenizer-feb5/tokenizer_config.json',\n",
       " '../../Output/model/gpt-tokenizer-feb5/special_tokens_map.json',\n",
       " '../../Output/model/gpt-tokenizer-feb5/vocab.json',\n",
       " '../../Output/model/gpt-tokenizer-feb5/merges.txt',\n",
       " '../../Output/model/gpt-tokenizer-feb5/added_tokens.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81249326-1640-4cb3-879a-95d16dbc8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training arguments with trained model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb50428-5226-4a66-95b1-9bce62d8f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a trained model and vocabulary that you have fine-tuned\n",
    "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
