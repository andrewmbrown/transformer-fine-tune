{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942973b4-5036-4845-8f76-88fceec6e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6622e2-24df-40eb-ad1b-01823c25f803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pyyaml (yaml) :: parses configuration files (YAML files)\n",
    "# see https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started for more information on YAML files\n",
    "import yaml \n",
    "\n",
    "# huggingface :: datasets : dataset-handling libraries from huggingface\n",
    "from datasets import load_dataset\n",
    "#from datasets.filesystems import S3FileSystem # for S3 interactions\n",
    "\n",
    "# huggingface :: transformers : transformer, trainer and tokenizer objects for the actual training\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# transformer_imports.py :: contains all our transformer imports and the MODEL DICT\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# pytorch (torch) :: machine learning and deep learning method library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f615c9-3e86-4566-8957-382ad72fd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027eaab0-abc3-4cec-b375-d5bdf2245067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk punkt sentence tokenizer, divides text into a list of sentences\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef5de79-8cc4-4b63-b5d5-a2bb874ea8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 27 18:15:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   36C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ab29e4-3481-4eb7-9170-bfb13c36509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-refl-27-mar-2023.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9d478-d8e4-45c9-b8e0-51be9d07d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open yaml config as a strema and load into config_dict\n",
    "with open(path_to_config, \"r\") as stream:\n",
    "    try:\n",
    "        config_dict = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Configuration load failed!\")\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607b596e-762a-4735-a413-00f094c030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_dict[\"data_train_path\"])\n",
    "df_val = pd.read_csv(config_dict[\"data_validation_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46f7a90-2ddc-4d32-9b54-de380dcfb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # drop NA values\n",
    "triplets = df.triplet.copy()  # copy over triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0eea85-8da6-4337-8aca-e8945c78c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_triplets = df_val.triplet.copy()  # validation triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839c2a2e-7c5c-4031-9a15-a929c4e3cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb950494510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how long is our training data?\n",
    "doc_lengths = []\n",
    "for triplet in triplets:\n",
    "    tokens = nltk.word_tokenize(triplet)\n",
    "    doc_lengths.append(len(tokens))\n",
    "doc_lengths = np.asarray(doc_lengths)\n",
    "sns.displot(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be28cbd-b469-486c-94a1-1b8fb23540cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.57807308970099"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(doc_lengths)\n",
    "# on average, we have ~47.5 tokens per entry, a good thing for GPT2 embedding size of 768 in gpt-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5bad70c-7c11-4cfb-9ad1-612444b2265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config_dict['model_name']\n",
    "hyperparameters = config_dict['training_settings']['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04be7ade-4c30-415d-b9c9-c4efe4dc6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load gpt-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2bdd305-2a1e-43bf-85f4-c1379d111765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|startoftext|> token has the id 50257\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The padding token <|pad|> has the id 50258\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074cb295-abc7-404d-9674-2f751e9863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of examples passed through model before a backwards pass\n",
    "batch_size = hyperparameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b4ddb39-4b65-475d-aa7d-89d28ffa7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    # Inherits Dataset from PyTorch, a data primitive which\n",
    "    # stores samples and corresponding labels\n",
    "    # custom Dataset needs init, len, and getitem\n",
    "    # init runs once when instantiating Dataset object\n",
    "    def __init__(self, txt_list, tokenzier, gpt2_type='gpt2-xl', max_length=1024):\n",
    "        self.tokenizer = tokenizer,\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        # for each text list, encode it using tokenizer then unpacl encodings dict into:\n",
    "        # input_ids: numerical representations of our tokens\n",
    "        # attn_masks: indicates which tokens should be attended to (and which are pads)\n",
    "        for txt in txt_list:\n",
    "            # tokenize the txt with a custom start and end token\n",
    "            # encodings dict contains both our token input ids and attention mask\n",
    "            # truncation will clip sentences that are too long\n",
    "            # padding adds pad tokens until we reach max input sentence length 768\n",
    "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            \n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    # overrides len() to returns the number of samples in our dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    # loads and returns a sample from dataset at given index idx\n",
    "    # sometimes we need to do type swapping in getitem, but not here\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17faab74-1b68-468e-bb7c-4b58bc6b93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2Dataset(triplets, tokenizer, max_length=1024)\n",
    "val_dataset = GPT2Dataset(val_triplets, tokenizer, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8e12d8e-66c1-47db-91a0-c3473a54f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 Training Samples\n",
      "34 Validation Samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_dataset)} Training Samples\")\n",
    "print(f\"{len(val_dataset)} Validation Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93400af7-95fd-4fea-af61-db8d864d0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and validation datasets\n",
    "# PyTorch DataLoaders wrap iterable around a Dataset to access samples easily\n",
    "# We typically pass in minibatches and reshuffle data at epochs to reduce overfitting\n",
    "# DataLoaders leverage python's multiprocessing to speed up data retrieval\n",
    "\n",
    "# take training samples in random order\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "# For validation, the order doesn't matter, so we read sequentially\n",
    "validation_dataloader = DataLoader(val_dataset,\n",
    "                                   sampler=SequentialSampler(val_dataset),\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab14844a-0bee-425d-9036-8b9e93c43f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to instantiate model\n",
    "configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2b34ca-76bd-4c8d-a2fa-820003e6efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffedcee-b6c7-43d8-b622-68527843efb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embeddings for our custom tokens (e.g. bos_token)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9dd3b69-eaea-4e7e-8de3-1d58a81ec9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ae74060-8628-4706-b597-14b2d8597a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sends model to current device - in this case CUDA\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5dc18a1-03e3-4c02-8d84-6e05af269bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f7befc2-c1be-4193-9a26-79debc388bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewbrown\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "time=\"2023-03-27T18:16:17Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230327_181617-ix0bfh8v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/gpt2-reflector/runs/ix0bfh8v\" target=\"_blank\">super-bird-7</a></strong> to <a href=\"https://wandb.ai/andrewbrown/gpt2-reflector\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/gpt2-reflector\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-reflector</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/gpt2-reflector/runs/ix0bfh8v\" target=\"_blank\">https://wandb.ai/andrewbrown/gpt2-reflector/runs/ix0bfh8v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/andrewbrown/gpt2-reflector/runs/ix0bfh8v?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb949604ed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"gpt2-reflector\",\n",
    "  notes=\"Hyperparameters found with sweep, final train -> push to HF\",\n",
    "  tags=[\"gpt2\", \"reflector\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d95614b-42d4-4ad2-9034-77929bbe71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the below set the corresponding values from the configuration file config.yaml:\n",
    "model_name = config_dict[\"model_name\"]\n",
    "pretrained = config_dict[\"pretrained\"]\n",
    "data_train_path = config_dict[\"data_train_path\"]\n",
    "data_validation_path = config_dict[\"data_validation_path\"]\n",
    "\n",
    "\n",
    "output_data_dir = config_dict[\"output_data_dir\"] + \"/\"\n",
    "output_model_dir = config_dict[\"output_model_dir\"] + \"/\"\n",
    "\n",
    "hyperparameters = config_dict[\"training_settings\"][\"hyperparameters\"]\n",
    "hyperparameters[\"learning_rate\"] = float(hyperparameters[\"learning_rate\"])\n",
    "hyperparameters[\"weight_decay\"] = float(hyperparameters[\"weight_decay\"])\n",
    "\n",
    "deepspeed_config = config_dict[\"training_settings\"][\"deepspeed_settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e37c038-3708-4c95-97d6-74f362438bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'find_hyperparams_automatically': False,\n",
       " 'num_trials': 10,\n",
       " 'fp16': True,\n",
       " 'deepspeed': True,\n",
       " 'grad_accumulation_steps': 2,\n",
       " 'eval_batch_size': 1,\n",
       " 'learning_rate': 0.050793350306270954,\n",
       " 'epochs': 10,\n",
       " 'warmup_steps': 100,\n",
       " 'epsilon': '1e-7',\n",
       " 'batch_size': 3,\n",
       " 'sample_every': 100,\n",
       " 'seed': 42,\n",
       " 'eval_steps': 10,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "699dc699-3354-4f52-b336-1d87d7cd39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = hyperparameters['learning_rate']\n",
    "epsilon = float(hyperparameters['epsilon'])  # epsilon must be a float, not str\n",
    "epochs = hyperparameters['epochs']\n",
    "warmup_steps = float(hyperparameters['warmup_steps'])\n",
    "sample_every = float(hyperparameters['sample_every'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab210284-b099-4bed-bdd5-63a2fcf5bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4590f1bd-04a3-42a7-974e-8d94530b2feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c625280e-dc33-4659-a9f6-049fafc486a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total num training steps is [num batches] x [num epochs]\n",
    "# (not the same number as num training sample)\n",
    "total_steps = len(train_dataloader) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38367cca-ce12-4eb0-bebc-81ebccc4bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate scheduler\n",
    "# we schedule learning rate using \n",
    "# optimzer, num_warmup steps, and num_training steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdba5811-ed9e-4393-94d7-94ee67da836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8393a344-2407-4719-b515-f75c3ad7af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.044084250926971436.   Elapsed: 0:01:32.\n",
      "0:  SahPrompt: What will it look like when you have made this change in your smoking habit?\n",
      "Response: You will be better will save money, your health will save lung capacity will be proud of smoking\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07224507286849588 ---\n",
      "---Training epoch took 0:01:32 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:03\n",
      "---Epoch 2 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.10192755609750748.   Elapsed: 0:01:33.\n",
      "0:  BryanPrompt: What will it look like when you have made this change in your smoking habit?\n",
      "Response: I think my sense of course\n",
      "Reflection: You believe you know your body.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07240249688672547 ---\n",
      "---Training epoch took 0:01:34 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:03\n",
      "---Epoch 3 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.06638983637094498.   Elapsed: 0:01:37.\n",
      "0:  spiritsPrompt: Now, what is the thing you like least about smoking?\n",
      "Response: bad in social aspect and smell of everything, especially a result of everything and clothes\n",
      "Reflection: Smoking are concerned about the nicotine pleas of smoking.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07227583969067229 ---\n",
      "---Training epoch took 0:01:38 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 4 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.10952933877706528.   Elapsed: 0:01:41.\n",
      "0:  seesPrompt: Now, what is one thing about your smoking habit that you would like to change?\n",
      "Response: Maybe I smoke less\n",
      "Reflection: You realize that you smoke in social settings.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.0724144362392697 ---\n",
      "---Training epoch took 0:01:42 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 5 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.01346272137016058.   Elapsed: 0:01:41.\n",
      "0:  hungryPrompt: To start, what is the thing you like most about smoking?\n",
      "Response: It\n",
      "Reflection: Tobacco cigarettes takes scent of smoking helps you feel\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.0718280670352944 ---\n",
      "---Training epoch took 0:01:41 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 6 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.05865932255983353.   Elapsed: 0:01:41.\n",
      "0:  PTPrompt: What will it look like when you have made this change in your smoking habit?\n",
      "Response: I will feel money, and the smell that once a better.\n",
      "Reflection: You believe you pass by smoking has.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07208412122165803 ---\n",
      "---Training epoch took 0:01:41 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 7 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.06326639652252197.   Elapsed: 0:01:41.\n",
      "0: Prompt: To start, what is the thing you like most about smoking?\n",
      "Response: the feeling on smoking helps you inhale causing me and use my parents and calm.\n",
      "Reflection: Smoking habit.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07254588135545796 ---\n",
      "---Training epoch took 0:01:41 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 8 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.11286480724811554.   Elapsed: 0:01:41.\n",
      "0: rucePrompt: Now, what is the thing you like least about smoking?\n",
      "Response: The smell and your feeling on your clothes.\n",
      "Reflection: You dislike how how time for your body and smoking makes that smoking makes you can kill you worry about a taste.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07285531730123676 ---\n",
      "---Training epoch took 0:01:41 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 9 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.0852726548910141.   Elapsed: 0:01:41.\n",
      "0:  derivativesPrompt: Finally, what are the steps you need to take to make this change?\n",
      "Response: I need to Stop smoking in order to quit when im other activities to make a conscious down. I'm you smoke, been a professional to quit smoking. \n",
      "Reflection: You realize that. You need to make to commit to decision of moments around smoking. You are strategies to make your bought to deal to you a concious with and trigger that smoking patch\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07260414164992843 ---\n",
      "---Training epoch took 0:01:43 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Epoch 10 of 10---\n",
      "---Training...---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    101. Loss: 0.09342725574970245.   Elapsed: 0:01:41.\n",
      "0: \u0019Prompt: Finally, what are the steps you need to take to make this change?\n",
      "Response: i need to go to finally stop smoking less and try to manage a lot gradually mechanism.\n",
      "Reflection: You realize that making this change and you want to have resistance to make a pack on being harm better and try more situations also have willpower and smoke.\n",
      "\n",
      "---Done Training Epoch!---\n",
      "---Average training loss 0.07230837820190014 ---\n",
      "---Training epoch took 0:01:42 ---\n",
      "---Running Validation...---\n",
      "Validation Loss: 0.11735399936636288\n",
      "Validation took: 0:00:04\n",
      "---Training Complete!\n",
      "---Total training time took 0:17:13\n"
     ]
    }
   ],
   "source": [
    "# start global timer\n",
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \"\"\"\n",
    "    Training Loop\n",
    "    \"\"\"\n",
    "    wandb.watch(model)\n",
    "    print(f\"---Epoch {epoch_i + 1} of {epochs}---\")\n",
    "    print(\"---Training...---\")\n",
    "    \n",
    "    # start epoch timer\n",
    "    t0 = time.time()\n",
    "    \n",
    "    total_train_loss = 0\n",
    "\n",
    "    # sets model into train mode, not actual backprop\n",
    "    # dropout and batchnorm behave differently\n",
    "    # opposite of model.eval() for inference mode\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # grab input tokens, labels, and masks\n",
    "        input_tokens = batch[0].to(device)\n",
    "        # in this case, we're generating text,\n",
    "        # so label tokens are the input tokens shifted\n",
    "        label_tokens = batch[0].to(device)\n",
    "        attn_masks = batch[1].to(device)\n",
    "        \n",
    "        # clear any gradients from model tensors\n",
    "        # prevents any gradient accumulation\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_tokens,\n",
    "                        labels=label_tokens,\n",
    "                        attention_mask=attn_masks,\n",
    "                        token_type_ids=None\n",
    "                       )\n",
    "        \n",
    "        # grab loss from outputs\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        batch_loss = loss.item()  # detach from device with item\n",
    "        total_train_loss += batch_loss\n",
    "        \n",
    "        # get sample every x batches\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "            # calculate elapsed time and print statistics\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "            \n",
    "            # set model to inference mode for testing\n",
    "            model.eval()\n",
    "            \n",
    "            # sample model with generate() using no tokens, just let it generate\n",
    "            sample_outputs = model.generate(bos_token_id=random.randint(1,30000),\n",
    "                                            do_sample=True,\n",
    "                                            top_k=50,\n",
    "                                            max_length=200,\n",
    "                                            top_p=0.95,\n",
    "                                            num_return_sequences=1\n",
    "                                           )\n",
    "            \n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "                print(f\"{i}: {out}\")\n",
    "            \n",
    "            # back to train mode\n",
    "        \n",
    "        # backpropagation step\n",
    "        # computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # updates gradient values\n",
    "        # x.grad += dloss/dx\n",
    "        loss.backward()\n",
    "        \n",
    "        # step optimizer\n",
    "        # updates the value of x using the gradient x.grad\n",
    "        # x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "        \n",
    "        # step scheduler\n",
    "        # tells scheduler to increase learning rate\n",
    "        # using our warmup steps\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(\"---Done Training Epoch!---\")\n",
    "    # calculate average loss over all batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    \n",
    "    # measure how long the epoch took\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(f\"---Average training loss {avg_train_loss} ---\")\n",
    "    print(f\"---Training epoch took {training_time} ---\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    print(\"---Running Validation...---\")\n",
    "    \n",
    "    # start batch timer\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # set model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    # evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # grab input tokens, labels, and masks\n",
    "        input_tokens = batch[0].to(device)\n",
    "        # in this case, we're generating text,\n",
    "        # so label tokens are the input tokens shifted\n",
    "        label_tokens = batch[0].to(device)\n",
    "        attn_masks = batch[1].to(device)\n",
    "        \n",
    "        # freeze gradients\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tokens,\n",
    "                            attention_mask=attn_masks,\n",
    "                            labels=label_tokens)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss\n",
    "        \n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "    print(f\"Validation took: {validation_time}\")\n",
    "    \n",
    "    # save all training statistics from the epoch\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        })\n",
    "    # log training data to wandb as well\n",
    "    wandb.log({\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        })\n",
    "    \n",
    "\n",
    "print(\"---Training Complete!\")\n",
    "print(f\"---Total training time took {format_time(time.time()-total_t0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f16de48c-372a-461e-92d2-0f87b15aee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:32</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:34</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:38</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:42</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:41</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:41</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:41</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:41</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:43</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0:01:42</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Validation Loss Training Time Validation Time\n",
       "epoch                                                              \n",
       "1               0.07             0.12       0:01:32         0:00:03\n",
       "2               0.07             0.12       0:01:34         0:00:03\n",
       "3               0.07             0.12       0:01:38         0:00:04\n",
       "4               0.07             0.12       0:01:42         0:00:04\n",
       "5               0.07             0.12       0:01:41         0:00:04\n",
       "6               0.07             0.12       0:01:41         0:00:04\n",
       "7               0.07             0.12       0:01:41         0:00:04\n",
       "8               0.07             0.12       0:01:41         0:00:04\n",
       "9               0.07             0.12       0:01:43         0:00:04\n",
       "10              0.07             0.12       0:01:42         0:00:04"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3929adad-19ed-40fd-890d-5f69b669aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Validation Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6c00054-512d-468f-bad7-c22d66e527b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPT-2 model has 148 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "transformer.wte.weight                                  (50259, 768)\n",
      "transformer.wpe.weight                                   (1024, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "transformer.h.0.ln_1.weight                                   (768,)\n",
      "transformer.h.0.ln_1.bias                                     (768,)\n",
      "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
      "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
      "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
      "transformer.h.0.attn.c_proj.bias                              (768,)\n",
      "transformer.h.0.ln_2.weight                                   (768,)\n",
      "transformer.h.0.ln_2.bias                                     (768,)\n",
      "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
      "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
      "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
      "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "transformer.ln_f.weight                                       (768,)\n",
      "transformer.ln_f.bias                                         (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:2]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[2:14]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e77b11c-7cc0-4d09-a559-c4dc5515669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_reflector(model, path_to_data, config_dict):\n",
    "    # import the data we are inferencing reflector with\n",
    "    # set of incomplete reflections which offer a good understanding of the reflector\n",
    "    df = pd.read_csv(path_to_data)\n",
    "    \n",
    "    # set model to inference mode for testing\n",
    "    model.eval()\n",
    "    \n",
    "    # de-nest yaml config\n",
    "    generation_config = config_dict['refgen']\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # sample model with generate() using no tokens, just let it generate\n",
    "        sample_outputs = model.generate(bos_token_id=random.randint(1,30000),\n",
    "                                        temperature = config['temperature'],\n",
    "                                        # flag to use a sampling technique or greedy\n",
    "                                        do_sample=config['do_sample'],\n",
    "                                        # penalize model for duplicating words\n",
    "                                        repetition_penalty = config['repetition_penalty'],\n",
    "                                        # of proposed words, only select from top k of them\n",
    "                                        top_k=config['top_k'],\n",
    "                                        # max amount of tokens to generate\n",
    "                                        max_length=config['max_length'],\n",
    "                                        # of propsed words, select from the words that add up to top_p value\n",
    "                                        # e.g. top_p=0.26 x(0.15),y(0.1),z(0.05)\n",
    "                                        # only select from x and y (0.15+0.1+0.05=0.3 which is too high)\n",
    "                                        top_p=config['top_p'],\n",
    "                                        # num of independently computed returned sequences for each element in the batch.\n",
    "                                        num_return_sequences=config['num_return_sequences']\n",
    "                                       )\n",
    "    \n",
    "        # after sampling model, decode tokens and print\n",
    "        for i, sample_output in enumerate(sample_outputs):\n",
    "            out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "            print(f\"===========================\")\n",
    "            print(f\"{i}: {out}\")\n",
    "            print(f\"===========================\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16b0e054-4eb8-48c6-8851-0239464f15c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1cb8611-80d2-469b-a44e-809d05e9f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the thing you like most about smoking?\n",
      "Response: I love the headrush I get from smoking.\n",
      "Reflection: You dislike the need to smoking can have made to replace smoking but you can help if you you smoke and you at other anxiety.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "generation_config = config_dict['refgen']\n",
    "config = config_dict\n",
    "\n",
    "text = \"Prompt: What is the thing you like most about smoking?\\nResponse: I love the headrush I get from smoking.\\n\"\n",
    "\n",
    "# encode the input text into tokens using the tokenizer\n",
    "tokenized_text = tokenizer.encode(\n",
    "    text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "encodings_dict = tokenizer('<|startoftext|>'+ text + '<|endoftext|>', truncation=True, max_length=1024, padding=\"max_length\")\n",
    "\n",
    "input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "input_ids = tokenized_text.to(device)\n",
    "\n",
    "# sample model with generate() using no tokens, just let it generate\n",
    "with torch.no_grad():\n",
    "    sample_outputs = model.generate(input_ids,\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    temperature = 0.8,\n",
    "                                    # flag to use a sampling technique or greedy\n",
    "                                    do_sample=generation_config['do_sample'],\n",
    "                                    # penalize model for duplicating words\n",
    "                                    repetition_penalty = 1.1,\n",
    "                                    # of proposed words, only select from top k of them\n",
    "                                    top_k=generation_config['top_k'],\n",
    "                                    # max amount of tokens to generate\n",
    "                                    max_length=1024,\n",
    "                                    # of propsed words, select from the words that add up to top_p value\n",
    "                                    # e.g. top_p=0.26 x(0.15),y(0.1),z(0.05)\n",
    "                                    # only select from x and y (0.15+0.1+0.05=0.3 which is too high)\n",
    "                                    top_p=generation_config['top_p'],\n",
    "                                    # num of independently computed returned sequences for each element in the batch.\n",
    "                                    num_return_sequences=1\n",
    "                                   )\n",
    "    output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5689d6a-934e-440e-906d-4325212bec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../models/gpt2-mi-reflector/\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the finetuned model\n",
    "output_dir = '../models/gpt2-mi-reflector/'\n",
    "tokenizer_dir = '../models/gpt2-mi-reflector/'\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(tokenizer_dir):\n",
    "    os.makedirs(tokenizer_dir)\n",
    "    \n",
    "    \n",
    "print(f\"Saving model to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ded92b74-16ff-4894-8fb4-a1fa20e7e76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/gpt2-mi-reflector/tokenizer_config.json',\n",
       " '../models/gpt2-mi-reflector/special_tokens_map.json',\n",
       " '../models/gpt2-mi-reflector/vocab.json',\n",
       " '../models/gpt2-mi-reflector/merges.txt',\n",
       " '../models/gpt2-mi-reflector/added_tokens.json')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81249326-1640-4cb3-879a-95d16dbc8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training arguments with trained model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb50428-5226-4a66-95b1-9bce62d8f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a trained model and vocabulary that you have fine-tuned\n",
    "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
