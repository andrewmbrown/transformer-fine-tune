{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6622e2-24df-40eb-ad1b-01823c25f803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pyyaml (yaml) :: parses configuration files (YAML files)\n",
    "# see https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started for more information on YAML files\n",
    "import yaml \n",
    "\n",
    "# huggingface :: datasets : dataset-handling libraries from huggingface\n",
    "from datasets import load_dataset\n",
    "#from datasets.filesystems import S3FileSystem # for S3 interactions\n",
    "\n",
    "# huggingface :: transformers : transformer, trainer and tokenizer objects for the actual training\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# transformer_imports.py :: contains all our transformer imports and the MODEL DICT\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# pytorch (torch) :: machine learning and deep learning method library\n",
    "import torch\n",
    "\n",
    "# deepspeed :: accelerator and memory management library\n",
    "import deepspeed\n",
    "\n",
    "# gradient checkpointing to fit larger models (when not even 1 batch fits)\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# nvidia management library, interface with gpu like nvidia-smi\n",
    "from pynvml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f615c9-3e86-4566-8957-382ad72fd41a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import nvidia_smi\n",
    "import wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0a2179-bd3d-4d51-9db8-283af5318a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_smi.nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027eaab0-abc3-4cec-b375-d5bdf2245067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk punkt sentence tokenizer, divides text into a list of sentences\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef5de79-8cc4-4b63-b5d5-a2bb874ea8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 10 03:00:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   17C    P8     9W / 300W |      0MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab442ab-2313-48a6-9f38-de884ff4c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a317b65b-5fb2-4005-9c31-412332bb6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ab29e4-3481-4eb7-9170-bfb13c36509d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-refl-04-apr-2023.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a9d478-d8e4-45c9-b8e0-51be9d07d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open yaml config as a strema and load into config_dict\n",
    "with open(path_to_config, \"r\") as stream:\n",
    "    try:\n",
    "        config_dict = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Configuration load failed!\")\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607b596e-762a-4735-a413-00f094c030b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_dict[\"data_train_path\"])\n",
    "df_val = pd.read_csv(config_dict[\"data_validation_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46f7a90-2ddc-4d32-9b54-de380dcfb35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # drop NA values\n",
    "triplets = df.triplet.copy()  # copy over triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0eea85-8da6-4337-8aca-e8945c78c2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_triplets = df_val.triplet.copy()  # validation triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "839c2a2e-7c5c-4031-9a15-a929c4e3cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fe81e15f790>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how long is our training data?\n",
    "doc_lengths = []\n",
    "for triplet in triplets:\n",
    "    tokens = nltk.word_tokenize(triplet)\n",
    "    doc_lengths.append(len(tokens))\n",
    "doc_lengths = np.asarray(doc_lengths)\n",
    "sns.displot(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be28cbd-b469-486c-94a1-1b8fb23540cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.53465346534654"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(doc_lengths)\n",
    "# on average, we have ~47.5 tokens per entry, a good thing for GPT2 embedding size of 768 in gpt-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5bad70c-7c11-4cfb-9ad1-612444b2265c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = config_dict['model_name']\n",
    "hyperparameters = config_dict['training_settings']['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf1d5f9-098e-42b0-833b-4fdd38d29af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2-xl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04be7ade-4c30-415d-b9c9-c4efe4dc6b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load gpt-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be6d3e9a-1e9b-44bb-a0bc-230a0c17dde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2bdd305-2a1e-43bf-85f4-c1379d111765",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|endoftext|> token has the id 50256\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The padding token <|endoftext|> has the id 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e90c3273-a64c-4b7f-b3e8-6e09d47e1256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-918e763cff422540\n",
      "Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-918e763cff422540/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 54.55it/s]\n",
      "Using custom data configuration default-851a0b80f47d644b\n",
      "Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-851a0b80f47d644b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 777.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['triplet'],\n",
      "        num_rows: 808\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['triplet'],\n",
      "        num_rows: 95\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('csv', data_files=config_dict['data_train_path'])\n",
    "raw_datasets[\"validation\"] = (load_dataset('csv', data_files=config_dict['data_validation_path']))[\"train\"]\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de38c28e-9099-4d33-8fda-1a674e8c6f98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIPLET: Prompt: Now, what is the thing you like least about smoking?\n",
      "Response: The medical risks\n",
      "Reflection: You are aware of the medical risks of smoking and you worry about what might happen if you do not quit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:256]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f7830ce-a4e0-4f27-a75e-3074b63d2eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#helper for tokenizing everything\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"triplet\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d7a71e-23d9-4c88-93b6-76ba3fded68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-918e763cff422540/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-55efa6181c76798b.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-851a0b80f47d644b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e04ddca8b942c703.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00dc62af-2a11-43ff-9280-0fc38d1eeaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['triplet', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 808\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['triplet', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 95\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7915517-e950-4c88-8eca-fcdc75b68efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"triplet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "074cb295-abc7-404d-9674-2f751e9863b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# amount of examples passed through model before a backwards pass\n",
    "batch_size = hyperparameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab14844a-0bee-425d-9036-8b9e93c43f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config to instantiate model\n",
    "configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f2b34ca-76bd-4c8d-a2fa-820003e6efba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ffedcee-b6c7-43d8-b622-68527843efb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 1600)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embeddings for our custom tokens (e.g. bos_token)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9dd3b69-eaea-4e7e-8de3-1d58a81ec9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ae74060-8628-4706-b597-14b2d8597a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (36): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (37): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (38): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (39): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (40): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (41): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (42): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (43): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (44): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (45): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (46): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (47): GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sends model to current device - in this case CUDA\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5dc18a1-03e3-4c02-8d84-6e05af269bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the seed value\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d95614b-42d4-4ad2-9034-77929bbe71b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all the below set the corresponding values from the configuration file config.yaml:\n",
    "model_name = config_dict[\"model_name\"]\n",
    "pretrained = config_dict[\"pretrained\"]\n",
    "data_train_path = config_dict[\"data_train_path\"]\n",
    "data_validation_path = config_dict[\"data_validation_path\"]\n",
    "\n",
    "\n",
    "output_data_dir = config_dict[\"output_data_dir\"] + \"/\"\n",
    "output_model_dir = config_dict[\"output_model_dir\"] + \"/\"\n",
    "\n",
    "hyperparameters = config_dict[\"training_settings\"][\"hyperparameters\"]\n",
    "hyperparameters[\"learning_rate\"] = float(hyperparameters[\"learning_rate\"])\n",
    "hyperparameters[\"weight_decay\"] = float(hyperparameters[\"weight_decay\"])\n",
    "\n",
    "deepspeed_config = config_dict[\"training_settings\"][\"deepspeed_settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e37c038-3708-4c95-97d6-74f362438bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'find_hyperparams_automatically': False,\n",
       " 'num_trials': 10,\n",
       " 'fp16': True,\n",
       " 'deepspeed': True,\n",
       " 'grad_accumulation_steps': 2,\n",
       " 'eval_batch_size': 1,\n",
       " 'learning_rate': 0.0003,\n",
       " 'epochs': 10,\n",
       " 'warmup_steps': 100,\n",
       " 'epsilon': '1e-7',\n",
       " 'batch_size': 1,\n",
       " 'sample_every': 100,\n",
       " 'seed': 42,\n",
       " 'eval_steps': 10,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "699dc699-3354-4f52-b336-1d87d7cd39a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = hyperparameters['learning_rate']\n",
    "epsilon = float(hyperparameters['epsilon'])  # epsilon must be a float, not str\n",
    "epochs = hyperparameters['epochs']\n",
    "warmup_steps = float(hyperparameters['warmup_steps'])\n",
    "sample_every = float(hyperparameters['sample_every'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9a5b907-ce94-4440-abd7-4c51057511e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2-xl'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70772cdd-92a9-47a0-900e-4230203f79de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os environment variables from HF for running deepspeed\n",
    "# deepspeed requires a distributed environment even when only one process is used\n",
    "# these environment variables emulate a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8868b60-c5ae-4b7a-8c3f-85d4625e7f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "async_io ............... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adam ............... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lamb ............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "random_ltd ............. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "sparse_attn ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "spatial_inference ...... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer_inference .. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "utils .................. \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch']\n",
      "torch version .................... 1.13.1+cu117\n",
      "deepspeed install path ........... ['/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.8.3, unknown, unknown\n",
      "torch cuda version ............... 11.7\n",
      "torch hip version ................ None\n",
      "nvcc version ..................... 11.0\n",
      "deepspeed wheel compiled w. ...... torch 1.13, cuda 11.7\n"
     ]
    }
   ],
   "source": [
    "!ds_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b56d-c733-4e10-8eff-13e32a2e8dad",
   "metadata": {},
   "source": [
    "## Deepspeed ZeRO\n",
    "\n",
    "ZeRO leverages aggregate computation and memory resources of data parallelism to reduce the memory and compute requirements of each GPU\n",
    "\n",
    "We partition various model training states (e.g. weights, gradients, and optimizer states) across available devices (GPUs and CPUs)\n",
    "\n",
    "Zero Redundancy Optimizer can be used at 3 levels (stages) of optimization. We configure deepspeed with a zero_optimization configuration file.\n",
    "\n",
    "In the file we specify which ZeRO stages we want enabled and how to configure them\n",
    "\n",
    "DeepSpeed doesn't validate parameter names so we must watch for misspelled parameters. We can use the DeepSpeed engine start up log to see what values its going to use \n",
    "\n",
    "Some configuration values are required by both the trainer and deepspeed (e.g. batch size) so we have to be careful about conflicting definitions\n",
    "\n",
    "Stage 2 and 3 are the most used versions of DeepSpeed, they provide the greatest ability to increase speed and reduce memory usage\n",
    "\n",
    "### ZeRO Stage 1 - Optimizer State Partitioning\n",
    "The optimizer states (e.g. Adam 32-bit weights, first, and second moment estimates) are partitioned across processes, so that each process only updates its own partition optimizer values\n",
    "\n",
    "### ZeRO Stage 2 - Gradient Partitioning\n",
    "The reduced 32-bit gradients for updating model weights are partitioned such that each process retains only the gradients corresponding to its portion of the optimizer states\n",
    "\n",
    "### ZeRO Stage 3 - Parameter Partitioning\n",
    "The 16-bit model parameters are partitioned across the processes. ZeRO-3 automatically collects and partitions them during forward and backward passes\n",
    "\n",
    "ZeRO-3 also includes infinity offload engine to offload memory or computation to the CPU and NVMe memory for huge savings\n",
    "\n",
    "Likely slower than ZeRO-2 if everything else is configured the same because the former has to gather model weights in addition to what ZeRO-2 does.\n",
    "If ZeRO-2 meets our needs we might be okay sticking to it.\n",
    "\n",
    "ZeRO-3 enables much higher scaling capacity at the cost of speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f8484-7718-4954-9a21-1198c20b3f15",
   "metadata": {},
   "source": [
    "When using DeepSpeed we want to find the fastest execution while fitting into minimal number of GPUs. We start with the fastest approach and if running into GPU OOM we go to the next slower approach (but with less GPU memory) and so on.\n",
    "\n",
    "Here is a rule of thumb for finding the best balance between speed and memory (first set batch size to 1 - later we'll use gradient accumulation to achieve desired batch size)\n",
    "\n",
    "1. Enable --gradient_checkpointing 1 (HF Trainer) or directly model.gradient_checkpointing_enable() - if OOM then\n",
    "\n",
    "2. Try ZeRO stage 2 first. if OOM then\n",
    "\n",
    "3. Try ZeRO stage 2 + offload_optimizer - if OOM then\n",
    "\n",
    "4. Switch to ZeRO stage 3 - if OOM then\n",
    "\n",
    "5. Enable offload_param to cpu - if OOM then\n",
    "\n",
    "6. Enable offload_optimizer to cpu - if OOM then\n",
    "\n",
    "7. If you still can’t fit a batch size of 1 first check various default values and lower them if you can. For example, if you use generate and you don’t use a wide search beam make it narrower as it’d take a lot of memory.\n",
    "\n",
    "8. Definitely use mixed half-precision over fp32 - so bf16 on Ampere and higher GPUs and fp16 on older gpu architectures.\n",
    "\n",
    "9. If you still OOM you could add more hardware or enable ZeRO-Infinity - that is switch offloads offload_param and offload_optimizer to nvme. You need to make sure it’s a very fast nvme. As an anecdote I was able to infer BLOOM-176B on a tiny GPU using ZeRO-Infinity except it was extremely slow. But it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d79b8f40-0fbe-4756-8cd8-e7c1dd9f2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad68bdc0-d744-4b83-a1f2-f31e6112caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = bnb.optim.Adam8bit(model.parameters(), lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "162e9430-0079-4f67-9182-3002fa816b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam8bit (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 1e-07\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f16f95bc-c5d9-42ee-a70a-ced0d5768ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-10 03:04:35,439] [INFO] [comm.py:654:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    }
   ],
   "source": [
    "# For gradient checkpointing, use HF training\n",
    "# I tried custom gradient checkpointing, but am getting issues with HF ecosystem + pytorch checkpointing\n",
    "# HF repository https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "# shows gradient checkpointing method, later i'll try pytorch lightning\n",
    "\n",
    "\n",
    "# HAVE TO MAKE SURE THAT THERE ARE NO CONFLICTS BETWEEN TRAINER CONFIG AND DEEPSPEED CONFIG!!!!!\n",
    "# using auto in deepspeed config allows us to avoid this\n",
    "training_args = TrainingArguments(output_dir=config_dict['output_model_dir'],\n",
    "                                overwrite_output_dir=True,\n",
    "                                deepspeed=\"../configs/ds_config_zero3.json\",\n",
    "                                bf16=True,\n",
    "                                evaluation_strategy = \"steps\", # used to be epoch\n",
    "                                prediction_loss_only = True, #get rid of this if we end up adding metrics\n",
    "                                logging_dir=f\"./logs/\",\n",
    "                                logging_strategy=\"steps\",\n",
    "                                logging_steps=5,\n",
    "                                save_strategy=\"no\",\n",
    "                                per_device_eval_batch_size=config_dict['training_settings']['hyperparameters'][\"eval_batch_size\"],\n",
    "                                learning_rate=config_dict['training_settings']['hyperparameters'][\"learning_rate\"],\n",
    "                                weight_decay=config_dict['training_settings']['hyperparameters'][\"weight_decay\"],\n",
    "                                num_train_epochs=config_dict['training_settings']['hyperparameters'][\"epochs\"],\n",
    "                                seed=config_dict['training_settings']['hyperparameters'][\"seed\"],\n",
    "                                per_device_train_batch_size=config_dict['training_settings']['hyperparameters'][\"batch_size\"],\n",
    "                                eval_steps=config_dict['training_settings']['hyperparameters'][\"eval_steps\"]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1c8be8d-ca3b-4ac8-b2b1-94ec056f29b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# constructs the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b686e7-7e23-4aaa-aa47-06d1316bb493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-10 03:04:36,525] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-04-10 03:04:36,600] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-04-10 03:04:40,128] [INFO] [logging.py:93:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2023-04-10 03:04:40,175] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-04-10 03:04:40,176] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-04-10 03:04:40,176] [INFO] [logging.py:93:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 3 optimizer\n",
      "[2023-04-10 03:04:40,297] [INFO] [utils.py:829:see_memory_usage] Stage 3 initialize beginning\n",
      "[2023-04-10 03:04:40,298] [INFO] [utils.py:834:see_memory_usage] MA 5.98 GB         Max_MA 5.98 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:40,299] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 4.56 GB, percent = 7.3%\n",
      "[2023-04-10 03:04:40,302] [INFO] [stage3.py:113:__init__] Reduce bucket size 2560000\n",
      "[2023-04-10 03:04:40,303] [INFO] [stage3.py:114:__init__] Prefetch bucket size 2304000\n",
      "[2023-04-10 03:04:40,408] [INFO] [utils.py:829:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2023-04-10 03:04:40,409] [INFO] [utils.py:834:see_memory_usage] MA 5.98 GB         Max_MA 5.98 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:40,410] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 4.56 GB, percent = 7.3%\n",
      "Parameter Offload: Total persistent parameters: 1001600 in 386 params\n",
      "[2023-04-10 03:04:43,727] [INFO] [utils.py:829:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2023-04-10 03:04:43,728] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 5.98 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:43,729] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 13.54 GB, percent = 21.8%\n",
      "[2023-04-10 03:04:43,837] [INFO] [utils.py:829:see_memory_usage] Before creating fp16 partitions\n",
      "[2023-04-10 03:04:43,839] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:43,840] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 13.54 GB, percent = 21.8%\n",
      "[2023-04-10 03:04:46,752] [INFO] [utils.py:829:see_memory_usage] After creating fp16 partitions: 2\n",
      "[2023-04-10 03:04:46,753] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:46,754] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 21.74 GB, percent = 35.0%\n",
      "[2023-04-10 03:04:46,862] [INFO] [utils.py:829:see_memory_usage] Before creating fp32 partitions\n",
      "[2023-04-10 03:04:46,863] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:46,864] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 21.74 GB, percent = 35.0%\n",
      "[2023-04-10 03:04:47,405] [INFO] [utils.py:829:see_memory_usage] After creating fp32 partitions\n",
      "[2023-04-10 03:04:47,406] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:47,407] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 27.55 GB, percent = 44.3%\n",
      "[2023-04-10 03:04:47,514] [INFO] [utils.py:829:see_memory_usage] Before initializing optimizer states\n",
      "[2023-04-10 03:04:47,515] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:47,516] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 27.55 GB, percent = 44.3%\n",
      "[2023-04-10 03:04:52,506] [INFO] [utils.py:829:see_memory_usage] After initializing optimizer states\n",
      "[2023-04-10 03:04:52,507] [INFO] [utils.py:834:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 6.0 GB         Max_CA 6 GB \n",
      "[2023-04-10 03:04:52,508] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 47.35 GB, percent = 76.2%\n",
      "[2023-04-10 03:04:52,509] [INFO] [stage3.py:376:_setup_for_real_optimizer] optimizer state initialized\n",
      "[2023-04-10 03:04:56,341] [INFO] [utils.py:829:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-04-10 03:04:56,343] [INFO] [utils.py:834:see_memory_usage] MA 0.06 GB         Max_MA 0.66 GB         CA 6.6 GB         Max_CA 7 GB \n",
      "[2023-04-10 03:04:56,344] [INFO] [utils.py:839:see_memory_usage] CPU Virtual Memory:  used = 55.52 GB, percent = 89.4%\n",
      "[2023-04-10 03:04:56,344] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2023-04-10 03:04:56,345] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2023-04-10 03:04:56,345] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fe81b225c90>\n",
      "[2023-04-10 03:04:56,346] [INFO] [logging.py:93:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0003], mom=[[0.9, 0.999]]\n",
      "[2023-04-10 03:04:56,347] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:\n",
      "[2023-04-10 03:04:56,348] [INFO] [config.py:1022:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-04-10 03:04:56,349] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-04-10 03:04:56,349] [INFO] [config.py:1022:print]   amp_enabled .................. False\n",
      "[2023-04-10 03:04:56,350] [INFO] [config.py:1022:print]   amp_params ................... False\n",
      "[2023-04-10 03:04:56,351] [INFO] [config.py:1022:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-04-10 03:04:56,351] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False\n",
      "[2023-04-10 03:04:56,352] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-04-10 03:04:56,352] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-04-10 03:04:56,353] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-04-10 03:04:56,354] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe815d80c10>\n",
      "[2023-04-10 03:04:56,354] [INFO] [config.py:1022:print]   communication_data_type ...... None\n",
      "[2023-04-10 03:04:56,355] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-04-10 03:04:56,355] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False\n",
      "[2023-04-10 03:04:56,356] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False\n",
      "[2023-04-10 03:04:56,356] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-04-10 03:04:56,356] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False\n",
      "[2023-04-10 03:04:56,357] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False\n",
      "[2023-04-10 03:04:56,358] [INFO] [config.py:1022:print]   disable_allgather ............ False\n",
      "[2023-04-10 03:04:56,359] [INFO] [config.py:1022:print]   dump_state ................... False\n",
      "[2023-04-10 03:04:56,359] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-04-10 03:04:56,360] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False\n",
      "[2023-04-10 03:04:56,360] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-04-10 03:04:56,360] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-04-10 03:04:56,361] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-04-10 03:04:56,361] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-04-10 03:04:56,362] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-04-10 03:04:56,362] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-04-10 03:04:56,363] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False\n",
      "[2023-04-10 03:04:56,363] [INFO] [config.py:1022:print]   elasticity_enabled ........... False\n",
      "[2023-04-10 03:04:56,364] [INFO] [config.py:1022:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-04-10 03:04:56,364] [INFO] [config.py:1022:print]   fp16_auto_cast ............... None\n",
      "[2023-04-10 03:04:56,364] [INFO] [config.py:1022:print]   fp16_enabled ................. False\n",
      "[2023-04-10 03:04:56,365] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-04-10 03:04:56,366] [INFO] [config.py:1022:print]   global_rank .................. 0\n",
      "[2023-04-10 03:04:56,366] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None\n",
      "[2023-04-10 03:04:56,366] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1\n",
      "[2023-04-10 03:04:56,367] [INFO] [config.py:1022:print]   gradient_clipping ............ 1.0\n",
      "[2023-04-10 03:04:56,367] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-04-10 03:04:56,368] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-04-10 03:04:56,368] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False\n",
      "[2023-04-10 03:04:56,368] [INFO] [config.py:1022:print]   loss_scale ................... 0\n",
      "[2023-04-10 03:04:56,369] [INFO] [config.py:1022:print]   memory_breakdown ............. False\n",
      "[2023-04-10 03:04:56,369] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-04-10 03:04:56,370] [INFO] [config.py:1022:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-04-10 03:04:56,370] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-04-10 03:04:56,370] [INFO] [config.py:1022:print]   optimizer_name ............... adamw\n",
      "[2023-04-10 03:04:56,371] [INFO] [config.py:1022:print]   optimizer_params ............. {'lr': 0.0003, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\n",
      "[2023-04-10 03:04:56,371] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-04-10 03:04:56,372] [INFO] [config.py:1022:print]   pld_enabled .................. False\n",
      "[2023-04-10 03:04:56,372] [INFO] [config.py:1022:print]   pld_params ................... False\n",
      "[2023-04-10 03:04:56,372] [INFO] [config.py:1022:print]   prescale_gradients ........... False\n",
      "[2023-04-10 03:04:56,373] [INFO] [config.py:1022:print]   scheduler_name ............... WarmupLR\n",
      "[2023-04-10 03:04:56,374] [INFO] [config.py:1022:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.0003, 'warmup_num_steps': 0}\n",
      "[2023-04-10 03:04:56,374] [INFO] [config.py:1022:print]   sparse_attention ............. None\n",
      "[2023-04-10 03:04:56,374] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False\n",
      "[2023-04-10 03:04:56,375] [INFO] [config.py:1022:print]   steps_per_print .............. 2000\n",
      "[2023-04-10 03:04:56,375] [INFO] [config.py:1022:print]   train_batch_size ............. 1\n",
      "[2023-04-10 03:04:56,375] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-04-10 03:04:56,376] [INFO] [config.py:1022:print]   use_node_local_storage ....... False\n",
      "[2023-04-10 03:04:56,376] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False\n",
      "[2023-04-10 03:04:56,377] [INFO] [config.py:1022:print]   world_size ................... 1\n",
      "[2023-04-10 03:04:56,377] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  False\n",
      "[2023-04-10 03:04:56,378] [INFO] [config.py:1022:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2560000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=2304000 param_persistence_threshold=16000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
      "[2023-04-10 03:04:56,378] [INFO] [config.py:1022:print]   zero_enabled ................. True\n",
      "[2023-04-10 03:04:56,378] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-04-10 03:04:56,379] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 3\n",
      "[2023-04-10 03:04:56,379] [INFO] [config.py:1013:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"zero_allow_untested_optimizer\": true, \n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.0003, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.01\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.0003, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 2.560000e+06, \n",
      "        \"stage3_prefetch_bucket_size\": 2.304000e+06, \n",
      "        \"stage3_param_persistence_threshold\": 1.600000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 808\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8080\n",
      "  Number of trainable parameters = 0\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewbrown\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "time=\"2023-04-10T03:04:59Z\" level=fatal msg=\"Failed to discover neuron devices\" error=\"Unable to read device information from the driver. Make sure aws-neuron-dkms is installed and the neuron driver is accessible.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/transformer-fine-tune/notebooks/wandb/run-20230410_030458-38h3v8z5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andrewbrown/huggingface/runs/38h3v8z5\" target=\"_blank\">frosty-galaxy-8</a></strong> to <a href=\"https://wandb.ai/andrewbrown/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andrewbrown/huggingface\" target=\"_blank\">https://wandb.ai/andrewbrown/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andrewbrown/huggingface/runs/38h3v8z5\" target=\"_blank\">https://wandb.ai/andrewbrown/huggingface/runs/38h3v8z5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000300, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:2388: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  \"torch.distributed._all_gather_base is a private function and will be \"\n",
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:2850: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  \"torch.distributed._reduce_scatter_base is a private function and will \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='8080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 351/8080 1:05:22 < 24:07:42, 0.09 it/s, Epoch 0.43/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.731900</td>\n",
       "      <td>2.806611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.718400</td>\n",
       "      <td>2.238543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.276900</td>\n",
       "      <td>2.395874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.553000</td>\n",
       "      <td>2.423612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.703800</td>\n",
       "      <td>2.214523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.146300</td>\n",
       "      <td>2.150342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.974200</td>\n",
       "      <td>2.134678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.382700</td>\n",
       "      <td>2.112824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.203100</td>\n",
       "      <td>2.213216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.205800</td>\n",
       "      <td>1.965171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.509100</td>\n",
       "      <td>2.153666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.468800</td>\n",
       "      <td>2.008904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.427500</td>\n",
       "      <td>2.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.053200</td>\n",
       "      <td>2.035963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.682600</td>\n",
       "      <td>2.098276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.203400</td>\n",
       "      <td>2.048496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.579900</td>\n",
       "      <td>1.946453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.995100</td>\n",
       "      <td>1.958451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.974200</td>\n",
       "      <td>1.981769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.491100</td>\n",
       "      <td>1.972130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.650600</td>\n",
       "      <td>2.033314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.397100</td>\n",
       "      <td>2.096131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.156400</td>\n",
       "      <td>1.943232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.407200</td>\n",
       "      <td>1.961294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.826500</td>\n",
       "      <td>1.923616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.407500</td>\n",
       "      <td>2.118217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.103500</td>\n",
       "      <td>2.070944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.238200</td>\n",
       "      <td>1.942149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.051700</td>\n",
       "      <td>2.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.727400</td>\n",
       "      <td>1.917454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.205500</td>\n",
       "      <td>1.904809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.246900</td>\n",
       "      <td>1.872128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.891300</td>\n",
       "      <td>1.895755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.802800</td>\n",
       "      <td>1.842040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/95 00:14 < 00:53, 1.39 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 1\n"
     ]
    }
   ],
   "source": [
    "trainer.train() #training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edcf36-77ef-4c1a-9c22-574c4a298146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generation_config = config_dict['refgen']\n",
    "config = config_dict\n",
    "\n",
    "text = \"Prompt: What do you want to change in your smoking?\\nResponse: I don't want to change anything in my smoking.\\n\"\n",
    "# encode the input text into tokens using the tokenizer\n",
    "tokenized_text = tokenizer.encode(\n",
    "    text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "encodings_dict = tokenizer(text, truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "input_ids = tokenized_text.to(device)\n",
    "\n",
    "# sample model with generate() using no tokens, just let it generate\n",
    "with torch.no_grad():\n",
    "    sample_outputs = model.generate(input_ids,\n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    temperature = 0.8,\n",
    "                                    # flag to use a sampling technique or greedy\n",
    "                                    do_sample=generation_config['do_sample'],\n",
    "                                    # penalize model for duplicating words\n",
    "                                    repetition_penalty = 1.1,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    # of proposed words, only select from top k of them\n",
    "                                    top_k=generation_config['top_k'],\n",
    "                                    # max amount of tokens to generate\n",
    "                                    max_length=256,\n",
    "                                    # of propsed words, select from the words that add up to top_p value\n",
    "                                    # e.g. top_p=0.26 x(0.15),y(0.1),z(0.05)\n",
    "                                    # only select from x and y (0.15+0.1+0.05=0.3 which is too high)\n",
    "                                    top_p=generation_config['top_p'],\n",
    "                                    # num of independently computed returned sequences for each element in the batch.\n",
    "                                    num_return_sequences=1\n",
    "                                   )\n",
    "    output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d176bcd8-372a-4419-8988-dd949367827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../models/gpt2-large-mi-reflector/\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the finetuned model\n",
    "output_dir = '../models/gpt2-large-mi-reflector/'\n",
    "tokenizer_dir = '../models/gpt2-large-mi-reflector/'\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(tokenizer_dir):\n",
    "    os.makedirs(tokenizer_dir)\n",
    "    \n",
    "    \n",
    "print(f\"Saving model to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5f2a223-1c68-4728-a269-9ca15be1409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../models/gpt2-large-mi-reflector/config.json\n",
      "Configuration saved in ../models/gpt2-large-mi-reflector/generation_config.json\n",
      "Model weights saved in ../models/gpt2-large-mi-reflector/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad9f6b33-cab6-4c0e-8243-7c6ddf8b9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../models/gpt2-large-mi-reflector/tokenizer_config.json\n",
      "Special tokens file saved in ../models/gpt2-large-mi-reflector/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/gpt2-large-mi-reflector/tokenizer_config.json',\n",
       " '../models/gpt2-large-mi-reflector/special_tokens_map.json',\n",
       " '../models/gpt2-large-mi-reflector/vocab.json',\n",
       " '../models/gpt2-large-mi-reflector/merges.txt',\n",
       " '../models/gpt2-large-mi-reflector/added_tokens.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a80f9fc-5034-4aa4-9068-53111f9ef76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training arguments with trained model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
