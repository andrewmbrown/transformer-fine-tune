{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6622e2-24df-40eb-ad1b-01823c25f803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pyyaml (yaml) :: parses configuration files (YAML files)\n",
    "# see https://www.cloudbees.com/blog/yaml-tutorial-everything-you-need-get-started for more information on YAML files\n",
    "import yaml \n",
    "\n",
    "# huggingface :: datasets : dataset-handling libraries from huggingface\n",
    "from datasets import load_dataset\n",
    "#from datasets.filesystems import S3FileSystem # for S3 interactions\n",
    "\n",
    "# huggingface :: transformers : transformer, trainer and tokenizer objects for the actual training\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# transformer_imports.py :: contains all our transformer imports and the MODEL DICT\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# pytorch (torch) :: machine learning and deep learning method library\n",
    "import torch\n",
    "\n",
    "# deepspeed :: accelerator and memory management library\n",
    "import deepspeed\n",
    "\n",
    "# gradient checkpointing to fit larger models (when not even 1 batch fits)\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# nvidia management library, interface with gpu like nvidia-smi\n",
    "from pynvml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f615c9-3e86-4566-8957-382ad72fd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import nvidia_smi\n",
    "import wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0a2179-bd3d-4d51-9db8-283af5318a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_smi.nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027eaab0-abc3-4cec-b375-d5bdf2245067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk punkt sentence tokenizer, divides text into a list of sentences\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef5de79-8cc4-4b63-b5d5-a2bb874ea8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  5 16:22:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P8    16W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab442ab-2313-48a6-9f38-de884ff4c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a317b65b-5fb2-4005-9c31-412332bb6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ab29e4-3481-4eb7-9170-bfb13c36509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../configs/gpt2-refl-04-apr-2023.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a9d478-d8e4-45c9-b8e0-51be9d07d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open yaml config as a strema and load into config_dict\n",
    "with open(path_to_config, \"r\") as stream:\n",
    "    try:\n",
    "        config_dict = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Configuration load failed!\")\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607b596e-762a-4735-a413-00f094c030b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_dict[\"data_train_path\"])\n",
    "df_val = pd.read_csv(config_dict[\"data_validation_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46f7a90-2ddc-4d32-9b54-de380dcfb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # drop NA values\n",
    "triplets = df.triplet.copy()  # copy over triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0eea85-8da6-4337-8aca-e8945c78c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_triplets = df_val.triplet.copy()  # validation triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "839c2a2e-7c5c-4031-9a15-a929c4e3cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f2c205e6d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how long is our training data?\n",
    "doc_lengths = []\n",
    "for triplet in triplets:\n",
    "    tokens = nltk.word_tokenize(triplet)\n",
    "    doc_lengths.append(len(tokens))\n",
    "doc_lengths = np.asarray(doc_lengths)\n",
    "sns.displot(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be28cbd-b469-486c-94a1-1b8fb23540cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.53465346534654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(doc_lengths)\n",
    "# on average, we have ~47.5 tokens per entry, a good thing for GPT2 embedding size of 768 in gpt-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5bad70c-7c11-4cfb-9ad1-612444b2265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config_dict['model_name']\n",
    "hyperparameters = config_dict['training_settings']['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf1d5f9-098e-42b0-833b-4fdd38d29af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2-large'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04be7ade-4c30-415d-b9c9-c4efe4dc6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6d3e9a-1e9b-44bb-a0bc-230a0c17dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2bdd305-2a1e-43bf-85f4-c1379d111765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|endoftext|> token has the id 50256\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The padding token <|endoftext|> has the id 50256\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90c3273-a64c-4b7f-b3e8-6e09d47e1256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-918e763cff422540\n",
      "Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-918e763cff422540/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 704.81it/s]\n",
      "Using custom data configuration default-851a0b80f47d644b\n",
      "Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-851a0b80f47d644b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 712.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['triplet'],\n",
      "        num_rows: 808\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['triplet'],\n",
      "        num_rows: 95\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset('csv', data_files=config_dict['data_train_path'])\n",
    "raw_datasets[\"validation\"] = (load_dataset('csv', data_files=config_dict['data_validation_path']))[\"train\"]\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de38c28e-9099-4d33-8fda-1a674e8c6f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIPLET: Prompt: Now, what is the thing you like least about smoking?\n",
      "Response: The medical risks\n",
      "Reflection: You are aware of the medical risks of smoking and you worry about what might happen if you do not quit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:256]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7830ce-a4e0-4f27-a75e-3074b63d2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper for tokenizing everything\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"triplet\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1d7a71e-23d9-4c88-93b6-76ba3fded68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-918e763cff422540/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-45d0eb2b097ab07b.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-851a0b80f47d644b/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-20d5b4a74cb50ca6.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00dc62af-2a11-43ff-9280-0fc38d1eeaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['triplet', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 808\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['triplet', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 95\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7915517-e950-4c88-8eca-fcdc75b68efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"triplet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074cb295-abc7-404d-9674-2f751e9863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of examples passed through model before a backwards pass\n",
    "batch_size = hyperparameters['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab14844a-0bee-425d-9036-8b9e93c43f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to instantiate model\n",
    "configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f2b34ca-76bd-4c8d-a2fa-820003e6efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ffedcee-b6c7-43d8-b622-68527843efb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 1280)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize token embeddings for our custom tokens (e.g. bos_token)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9dd3b69-eaea-4e7e-8de3-1d58a81ec9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ae74060-8628-4706-b597-14b2d8597a31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sends model to current device - in this case CUDA\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5dc18a1-03e3-4c02-8d84-6e05af269bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d95614b-42d4-4ad2-9034-77929bbe71b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all the below set the corresponding values from the configuration file config.yaml:\n",
    "model_name = config_dict[\"model_name\"]\n",
    "pretrained = config_dict[\"pretrained\"]\n",
    "data_train_path = config_dict[\"data_train_path\"]\n",
    "data_validation_path = config_dict[\"data_validation_path\"]\n",
    "\n",
    "\n",
    "output_data_dir = config_dict[\"output_data_dir\"] + \"/\"\n",
    "output_model_dir = config_dict[\"output_model_dir\"] + \"/\"\n",
    "\n",
    "hyperparameters = config_dict[\"training_settings\"][\"hyperparameters\"]\n",
    "hyperparameters[\"learning_rate\"] = float(hyperparameters[\"learning_rate\"])\n",
    "hyperparameters[\"weight_decay\"] = float(hyperparameters[\"weight_decay\"])\n",
    "\n",
    "deepspeed_config = config_dict[\"training_settings\"][\"deepspeed_settings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e37c038-3708-4c95-97d6-74f362438bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'find_hyperparams_automatically': False,\n",
       " 'num_trials': 10,\n",
       " 'fp16': True,\n",
       " 'deepspeed': True,\n",
       " 'grad_accumulation_steps': 2,\n",
       " 'eval_batch_size': 1,\n",
       " 'learning_rate': 0.0003,\n",
       " 'epochs': 10,\n",
       " 'warmup_steps': 100,\n",
       " 'epsilon': '1e-7',\n",
       " 'batch_size': 1,\n",
       " 'sample_every': 100,\n",
       " 'seed': 42,\n",
       " 'eval_steps': 10,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "699dc699-3354-4f52-b336-1d87d7cd39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = hyperparameters['learning_rate']\n",
    "epsilon = float(hyperparameters['epsilon'])  # epsilon must be a float, not str\n",
    "epochs = hyperparameters['epochs']\n",
    "warmup_steps = float(hyperparameters['warmup_steps'])\n",
    "sample_every = float(hyperparameters['sample_every'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9a5b907-ce94-4440-abd7-4c51057511e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt2-large'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70772cdd-92a9-47a0-900e-4230203f79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os environment variables from HF for running deepspeed\n",
    "# deepspeed requires a distributed environment even when only one process is used\n",
    "# these environment variables emulate a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8868b60-c5ae-4b7a-8c3f-85d4625e7f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "random_ltd ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m please install triton==1.0.0 if you want to use sparse attention\n",
      "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch']\n",
      "torch version .................... 1.13.1+cu117\n",
      "deepspeed install path ........... ['/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.8.3, unknown, unknown\n",
      "torch cuda version ............... 11.7\n",
      "torch hip version ................ None\n",
      "nvcc version ..................... 11.0\n",
      "deepspeed wheel compiled w. ...... torch 1.13, cuda 11.7\n"
     ]
    }
   ],
   "source": [
    "!ds_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b56d-c733-4e10-8eff-13e32a2e8dad",
   "metadata": {},
   "source": [
    "## Deepspeed ZeRO\n",
    "\n",
    "ZeRO leverages aggregate computation and memory resources of data parallelism to reduce the memory and compute requirements of each GPU\n",
    "\n",
    "We partition various model training states (e.g. weights, gradients, and optimizer states) across available devices (GPUs and CPUs)\n",
    "\n",
    "Zero Redundancy Optimizer can be used at 3 levels (stages) of optimization. We configure deepspeed with a zero_optimization configuration file.\n",
    "\n",
    "In the file we specify which ZeRO stages we want enabled and how to configure them\n",
    "\n",
    "DeepSpeed doesn't validate parameter names so we must watch for misspelled parameters. We can use the DeepSpeed engine start up log to see what values its going to use \n",
    "\n",
    "Some configuration values are required by both the trainer and deepspeed (e.g. batch size) so we have to be careful about conflicting definitions\n",
    "\n",
    "Stage 2 and 3 are the most used versions of DeepSpeed, they provide the greatest ability to increase speed and reduce memory usage\n",
    "\n",
    "### ZeRO Stage 1 - Optimizer State Partitioning\n",
    "The optimizer states (e.g. Adam 32-bit weights, first, and second moment estimates) are partitioned across processes, so that each process only updates its own partition optimizer values\n",
    "\n",
    "### ZeRO Stage 2 - Gradient Partitioning\n",
    "The reduced 32-bit gradients for updating model weights are partitioned such that each process retains only the gradients corresponding to its portion of the optimizer states\n",
    "\n",
    "### ZeRO Stage 3 - Parameter Partitioning\n",
    "The 16-bit model parameters are partitioned across the processes. ZeRO-3 automatically collects and partitions them during forward and backward passes\n",
    "\n",
    "ZeRO-3 also includes infinity offload engine to offload memory or computation to the CPU and NVMe memory for huge savings\n",
    "\n",
    "Likely slower than ZeRO-2 if everything else is configured the same because the former has to gather model weights in addition to what ZeRO-2 does.\n",
    "If ZeRO-2 meets our needs we might be okay sticking to it.\n",
    "\n",
    "ZeRO-3 enables much higher scaling capacity at the cost of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f16f95bc-c5d9-42ee-a70a-ced0d5768ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-05 16:23:18,071] [INFO] [comm.py:654:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    }
   ],
   "source": [
    "# For gradient checkpointing, use HF training\n",
    "# I tried custom gradient checkpointing, but am getting issues with HF ecosystem + pytorch checkpointing\n",
    "# HF repository https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "# shows gradient checkpointing method, later i'll try pytorch lightning\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=config_dict['output_model_dir'],\n",
    "                                overwrite_output_dir=True,\n",
    "                                fp16 = config_dict['training_settings']['hyperparameters'][\"fp16\"],\n",
    "                                deepspeed=\"../configs/ds_config_zero3.json\",\n",
    "                                evaluation_strategy = \"steps\", # used to be epoch\n",
    "                                prediction_loss_only = True, #get rid of this if we end up adding metrics\n",
    "                                logging_dir=f\"./logs/\",\n",
    "                                logging_strategy=\"steps\",\n",
    "                                logging_steps=5,\n",
    "                                save_strategy=\"no\",\n",
    "                                per_device_eval_batch_size=config_dict['training_settings']['hyperparameters'][\"eval_batch_size\"],\n",
    "                                gradient_accumulation_steps=config_dict['training_settings']['hyperparameters'][\"grad_accumulation_steps\"],\n",
    "                                learning_rate=config_dict['training_settings']['hyperparameters'][\"learning_rate\"],\n",
    "                                weight_decay=config_dict['training_settings']['hyperparameters'][\"weight_decay\"],\n",
    "                                num_train_epochs=config_dict['training_settings']['hyperparameters'][\"epochs\"],\n",
    "                                seed=config_dict['training_settings']['hyperparameters'][\"seed\"],\n",
    "                                per_device_train_batch_size=config_dict['training_settings']['hyperparameters'][\"batch_size\"],\n",
    "                                eval_steps=config_dict['training_settings']['hyperparameters'][\"eval_steps\"]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "212f3601-779a-41e8-8e0f-bdbfb515cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  5 16:23:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   33C    P0    58W / 300W |   3897MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3348      C   ...s/torch_p37/bin/python3.7     3895MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1c8be8d-ca3b-4ac8-b2b1-94ec056f29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# constructs the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25b686e7-7e23-4aaa-aa47-06d1316bb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-05 16:23:47,032] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown\n",
      "[2023-04-05 16:23:47,404] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-04-05 16:23:48,955] [WARNING] [cpu_adam.py:86:__init__] FP16 params for CPUAdam may not work on AMD CPUs\n",
      "Installed CUDA version 11.0 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ubuntu/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...\n",
      "Creating extension directory /home/ubuntu/.cache/torch_extensions/py37_cu117/cpu_adam...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py37_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/TH -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
      "FAILED: custom_cuda_kernel.cuda.o \n",
      "/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/TH -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
      "nvcc fatal   : Unsupported gpu architecture 'compute_86'\n",
      "[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/TH -isystem /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/anaconda3/envs/torch_p37/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -c /home/ubuntu/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
      "ninja: build stopped: subcommand failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'cpu_adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1905\u001b[0m             \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m             env=env)\n\u001b[0m\u001b[1;32m   1907\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3348/2214871586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#training time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m         )\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             deepspeed_engine, optimizer, lr_scheduler = deepspeed_init(\n\u001b[0;32m-> 1613\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m             )\n\u001b[1;32m   1615\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepspeed_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/transformers/deepspeed.py\u001b[0m in \u001b[0;36mdeepspeed_init\u001b[0;34m(trainer, num_training_steps, resume_from_checkpoint, inference)\u001b[0m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mdeepspeed_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/__init__.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    133\u001b[0m                                  \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                                  \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                                  config_params=config_params)\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mpu must be None with pipeline parallelism\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_params, dont_change_device)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m_configure_optimizer\u001b[0;34m(self, client_optimizer, model_parameters)\u001b[0m\n\u001b[1;32m   1281\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mZeRORuntimeException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m             \u001b[0mbasic_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_basic_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             log_dist(\n\u001b[1;32m   1285\u001b[0m                 \u001b[0;34mf\"Using DeepSpeed Optimizer param name {self.optimizer_name()} as basic optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m_configure_basic_optimizer\u001b[0;34m(self, model_parameters)\u001b[0m\n\u001b[1;32m   1354\u001b[0m                         optimizer = DeepSpeedCPUAdam(model_parameters,\n\u001b[1;32m   1355\u001b[0m                                                      \u001b[0;34m**\u001b[0m\u001b[0moptimizer_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m                                                      adamw_mode=effective_adam_w_mode)\n\u001b[0m\u001b[1;32m   1357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                     \u001b[0;32mfrom\u001b[0m \u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/adam/cpu_adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_params, lr, bias_correction, betas, eps, weight_decay, amsgrad, adamw_mode, fp32_optimizer_states)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam_w_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madamw_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_optimizer_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp32_optimizer_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_opt_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPUAdamBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         self.ds_opt_adam.create_adam(self.opt_id,\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/op_builder/builder.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjit_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/deepspeed/ops/op_builder/builder.py\u001b[0m in \u001b[0;36mjit_load\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mextra_cuda_cflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_empty_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvcc_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mextra_ldflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_empty_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_ldflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mbuild_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mis_python_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mis_standalone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         keep_intermediates=keep_intermediates)\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1516\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                         \u001b[0mwith_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m                         is_standalone=is_standalone)\n\u001b[0m\u001b[1;32m   1519\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mbaton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         error_prefix=f\"Error building extension '{name}'\")\n\u001b[0m\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_p37/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\": {error.output.decode(*SUBPROCESS_DECODE_ARGS)}\"\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'cpu_adam'"
     ]
    }
   ],
   "source": [
    "trainer.train() #training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edcf36-77ef-4c1a-9c22-574c4a298146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generation_config = config_dict['refgen']\n",
    "config = config_dict\n",
    "\n",
    "text = \"Prompt: What do you want to change in your smoking?\\nResponse: I don't want to change anything in my smoking.\\n\"\n",
    "# encode the input text into tokens using the tokenizer\n",
    "tokenized_text = tokenizer.encode(\n",
    "    text, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "encodings_dict = tokenizer(text, truncation=True, max_length=256, padding=\"max_length\")\n",
    "\n",
    "input_ids = torch.tensor(encodings_dict['input_ids'])\n",
    "input_ids = tokenized_text.to(device)\n",
    "\n",
    "# sample model with generate() using no tokens, just let it generate\n",
    "with torch.no_grad():\n",
    "    sample_outputs = model.generate(input_ids,\n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    temperature = 0.8,\n",
    "                                    # flag to use a sampling technique or greedy\n",
    "                                    do_sample=generation_config['do_sample'],\n",
    "                                    # penalize model for duplicating words\n",
    "                                    repetition_penalty = 1.1,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    # of proposed words, only select from top k of them\n",
    "                                    top_k=generation_config['top_k'],\n",
    "                                    # max amount of tokens to generate\n",
    "                                    max_length=256,\n",
    "                                    # of propsed words, select from the words that add up to top_p value\n",
    "                                    # e.g. top_p=0.26 x(0.15),y(0.1),z(0.05)\n",
    "                                    # only select from x and y (0.15+0.1+0.05=0.3 which is too high)\n",
    "                                    top_p=generation_config['top_p'],\n",
    "                                    # num of independently computed returned sequences for each element in the batch.\n",
    "                                    num_return_sequences=1\n",
    "                                   )\n",
    "    output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d176bcd8-372a-4419-8988-dd949367827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../models/gpt2-large-mi-reflector/\n"
     ]
    }
   ],
   "source": [
    "# saving and loading the finetuned model\n",
    "output_dir = '../models/gpt2-large-mi-reflector/'\n",
    "tokenizer_dir = '../models/gpt2-large-mi-reflector/'\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(tokenizer_dir):\n",
    "    os.makedirs(tokenizer_dir)\n",
    "    \n",
    "    \n",
    "print(f\"Saving model to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5f2a223-1c68-4728-a269-9ca15be1409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../models/gpt2-large-mi-reflector/config.json\n",
      "Configuration saved in ../models/gpt2-large-mi-reflector/generation_config.json\n",
      "Model weights saved in ../models/gpt2-large-mi-reflector/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad9f6b33-cab6-4c0e-8243-7c6ddf8b9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../models/gpt2-large-mi-reflector/tokenizer_config.json\n",
      "Special tokens file saved in ../models/gpt2-large-mi-reflector/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/gpt2-large-mi-reflector/tokenizer_config.json',\n",
       " '../models/gpt2-large-mi-reflector/special_tokens_map.json',\n",
       " '../models/gpt2-large-mi-reflector/vocab.json',\n",
       " '../models/gpt2-large-mi-reflector/merges.txt',\n",
       " '../models/gpt2-large-mi-reflector/added_tokens.json')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a80f9fc-5034-4aa4-9068-53111f9ef76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training arguments with trained model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, 'training_args.bin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
